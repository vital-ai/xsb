%====================================================================

\chapter{Using Tabling in XSB: A Tutorial Introduction} 
\label{chap:TablingOverview}

XSB has two ways of evaluating predicates.  The default is to use
Prolog-style evaluation, but by using various declarations a
programmer can also use tabled resolution which can provide a
different, more declarative programming style than Prolog.  In this
section we discuss various aspects of tabling and their implementation
in XSB\@.  Our aim in this section is to provide a user with enough
information to be able to program productively with tables in XSB\@.
It is best to read this tutorial with a copy of XSB handy, since much
of the information is presented through a series of exercises.

For the theoretically inclined, XSB uses SLG resolution which can
compute queries to non-floundering normal programs under the
well-founded semantics~\cite{VGRS91}, and is guaranteed to terminate
when these programs have the {\em bounded term-depth property}.  This
tutorial covers only enough of the theory of tabling to explain how to
program in XSB\@.  For those interested, the web site contains papers
covering in detail various aspects of tabling (often through the links
for individuals involved in XSB)\@.  An overview of SLG resolution,
and practical evaluation strategies for it, are provided
in~\cite{ChWa96,Swif99b,SaSW99,FSW98}.  The engine of XSB, the
SLG-WAM, is an extension of the WAM \cite{DHWa83,AitK90}, and is
described in~\cite{SaSw98,RRSSW98,JFLP-Scheduling,SaSW96,
  ChSW95,CAT@PLILP-98,TST99,CuSW99b,CuiW00,CaSW02,MarS08b,Swif09a,MarS10,SwiW10a}
as it is implemented in \version{} and its performance
analyzed. Examples of large-scale applications that use tabling are
overviewed in~\cite{syntactica, semantica, CoDS96, DRW96, RRRSSW97,
  Boul97,CuSW99a,GSTPD00,SwiW12}.

%=====================================================================

\section{Tabling in the Context of a Prolog System}
\label{tabling_env}

Before describing how to program using tabling it is perhaps
worthwhile to review some of the goals of XSB's implementation of
tabling.  Among them are:
\begin{enumerate}
\item	To execute tabled predicates at the speed of compiled Prolog.
\item	To ensure that the speed of compiled Prolog is not slowed
	significantly by adding the option of tabling.
\item	To ensure that the functionality of Prolog is not compromised
 	by support for tabling.
\item   To provide Prolog functionality in tabled predicates and
	operators whenever it is semantically sensible to do so.
\item	To provide standard predicates to manipulate tables
	taken as data structures in themselves.
\end{enumerate}

Goals 1 and 2 are addressed by XSB's engine, which in \version{} is
based on a virtual machine called the SLG-WAM\@.  The overhead for SLD
resolution using this machine is small, and usually less than 5\%.
Thus when XSB is used simply as a Prolog system (i.e., no tabling is
used), it is reasonably competitive with other Prolog implementations
based on a WAM emulator written in C or assembly.  For example, when
compiled as a threaded interpreter (see Chapter~\ref{system}) XSB
\version\ is about two times slower than Quintus 3.1.1 or emulated
SICStus Prolog 3.1.
%
Goals 3, 4 and 5 have been nearly met, but there are a few instances
in which interaction of tabling with a Prolog construct has not been
accomplished, or is perhaps impossible.  Accordingly we discuss these
instances throughout this chapter.  XSB is still under development
however, so that future versions may support more transparent mixing
of Prolog and tabled code.
\comment{
 (e.g. allowing tabled predicates in the
scope of \verb|\+/1|) or adding Prolog functionality to tabled
predicates or operators (e.g. allowing non-ground negation in {\tt
tnot/1}).
}
%=====================================================================

\section{Definite Programs}
\label{sec:def}

Definite programs, also called \emph{Horn Clause Programs}, are Prolog
programs without negation or aggregation.  In XSB, this means without
the \verb|\+/1|, {\tt fail\_if/1}, {\tt not/1}, {\tt tnot/1}, {\tt
  setof/3}, {\tt bagof/3}, {\tt tt findall/3} or other aggregation
operators.  Consider the Prolog program
\begin{center}
\begin{minipage}{3.8in}
\begin{verbatim}
path(X,Y) :- path(X,Z), edge(Z,Y).
path(X,Y) :- edge(X,Y).
\end{verbatim}						       
\end{minipage}
\end{center}
together with the query {\tt ?- path(1,Y)}.  This program has a
simple, declarative meaning: there is a path from {\tt X} to {\tt Y}
if there is a path from {\tt X} to some node {\tt Z} and there is an
edge from {\tt Z} to {\tt Y}, or if there is an edge from {\tt X} to
{\tt Y}\@.  Prolog, however, enters into an infinite loop when
computing an answer to this query.  The inability of Prolog to answer
such queries, which arise frequently, comprises one of its major
limitations as an implementation of logic.

A number of approaches have been developed to address this problem by
reusing partial answers to the query {\tt path(1,Y)}
\cite{Diet87,TaSa86,BMSU86,Viei89,Walk93}.  The ideas behind these
algorithms can be described in the following manner.  Calls to tabled
predicates, such as {\tt path(1,Y)} in the above example, are stored
in a searchable structure together with their proven instances.  This
collection of \emph{tabled subgoals} paired with their \emph{answers},
generally referred to as a \emph{table}, is consulted whenever a new
call, $C$, to a tabled predicate is issued.  If $C$ is sufficiently
similar to a tabled subgoal $S$, then the set of answers, $\cA$,
associated with $S$ may be used to satisfy $C$.
%\footnote{We use
%the term ``answer set'' to describe the set of answers associated with
%a given subgoal during a given state of computation.  As such, it has
%no relation to the use of the term ``answer set'' in the non-monotonic
%literature.}\@.  
In such instances, $C$ is resolved against the answers in $\cA$, and
hence we refer to the call $C$ as a
\emph{consumer}\index{tabling!consumer} of $\cA$ (or $S$)\@.  If there
is no such $S$, then $C$ is entered into the table and is resolved
against program clauses as in Prolog~---~i.e., using SLD~resolution.
As each answer is derived during this process, it is inserted into the
table entry associated with $C$ if it contains information not already
in $\cA$\@.  In this second case, we refer to $C$ as a
\emph{generator}, or \emph{producer}\index{tabling!producer,
  generator}, as resolution of $C$ in this manner produces the answers
stored in its table entry.  If the answer is in fact added to this
set, then it is additionally scheduled to be returned to all consumers
of $C$\@.  If instead it is rejected as redundant, then the evaluation
simply fails and backtracks to generate more answers.

Notice that since consuming subgoals resolve against unique answers
rather than repeatedly against program clauses, tabling will terminate
whenever
\begin{enumerate}
\item a finite number of subgoals are encountered during query
      evaluation, and
\item each of these subgoals has a finite number of answers.
\end{enumerate}
Indeed, it can be proven that for any program with the \emph{bounded
term depth property}~---~roughly, where all terms generated in a
program have a maximum depth~---~SLG computation will terminate.
These programs include the important class of \emph{Datalog} programs.

%--------------------------------------------------------------------
Predicates can be declared tabled in a variety of ways.  A common form
is the compiler directive \stdrefindex{table/1}
\[
	\verb|:- table | P_1, \ldots, P_n.
\]
where each $P_i$ is a predicate indicator or callable term.  More
generally 
\[
	\verb|:- table | P_1, \ldots, P_n\ {\tt as\ }Options.
\]
allows a user to specify different types of tabling through {\tt
  Options} along with other properties of the designated predicates
For static predicates, these directives must be added to the file
containing the clauses of the predicate(s) to be tabled, and the
directives cause the predicates to be compiled with
tabling~\footnote{In \version, tabling does not work together with
  multi-file predicates.}.  For dynamic predicates, the executable
directives
\[
       \verb| ?- table | P_1, \ldots P_n.
\]
and 
\[
	\verb|?- table | P_1, \ldots, P_n\ {\tt as\ }Options.
\]
cause a $P_i$ to be tabled (with the appropriate options) if no
clauses have been asserted for $P_i$.

\paragraph{Exercises}
Unless otherwise noted, the file
\textup{\texttt{\$XSB\_DIR/examples/table\_examples.P}} contains all
the code for the running examples in this section.  Invoke XSB with its
default settings (i.e., don't supply additional options) when working
through the following exercises.

\begin{exercise}
Consult \textup{\texttt{\$XSB\_DIR/examples/table\_examples.P}} into
XSB and and try the goal
\begin{verbatim}
         ?- path(1,X).
\end{verbatim}
and continue typing \verb|;<RETURN>| until you have exhausted all
answers.  Now, try rewriting the \code{path/2} predicate as it would
be written in Prolog~---~and without a tabling declaration.  Will it
now terminate for the provided {\tt edge/2} relation?  (Remember, in
XSB you can always hit \verb|<ctrl>-C| if you go into an infinite
loop).\fillBox
\end{exercise}

The return of answers in tabling aids in filtering out redundant
computations -- indeed it is this property which makes tabling
terminate for many classes of programs.  The {\tt same generation}
program furnishes a case of the usefulness of tabling for optimizing a
Prolog program.

\begin{exercise} \label{ex:samegen}
If you are {\em still} curious, load in the file {\tt cyl.P} in the
\verb|$XSB_DIR/examples| directory using the command.  %$
\begin{verbatim}
         ?- load_dync(cyl.P).
\end{verbatim}
and then type the query
\begin{verbatim}
         ?- same_generation(X,X),fail.
\end{verbatim}
Now rewrite the {\tt same\_generation/2} program so that it does not
use tabling and retry the same query.  What happens?  (Be
patient~---~or use \verb|<ctrl>-C|).\fillBox
\end{exercise}

\begin{exercise}
The file {\tt table\_examples.P} contains a set of facts
\begin{verbatim}
         ordered_goal(one).
         ordered_goal(two).
         ordered_goal(three).
         ordered_goal(four).
\end{verbatim}
Clearly, the query {\tt ?- ordered\_goal(X)} will return the answers
in the expected order.  {\tt table\_examples.P} also contains a predicate
\begin{verbatim}
         :- table table_ordered_goal/1.
         table_ordered_goal(X):- ordered_goal(X).
\end{verbatim}
which simply calls {\tt ordered\_goal/1} and tables its answers
(tabling is unnecessary in this case, and is only used for
illustration).  Call the query {\tt ?- table\_ordered\_goal(X)} and
backtrack through the answers.  In what order are the answers
returned?
\end{exercise}
%-------------------------------------------------------------------------
\comment{
\begin{exercise}
Consult this file into XSB and type the query
\begin{verbatim}
         ?- path(1,Y).
\end{verbatim}
and continue typing \verb|;<RETURN>| until you have exhausted all
answers.  Type the query again.  Can you guess why the order of
answers is different?  Now type
\begin{verbatim}
         ?- abolish_all_tables.
\end{verbatim}
and retry the \code{path/2} query.\fillBox
\end{exercise}
}
%-------------------------------------------------------------------------
\index{termination}
The examples stress two differences between tabling and SLD resolution
beyond termination properties.  First, that each solution to a tabled
subgoal is returned only once~---~a property that is helpful not only
for {\tt path/2} but also for {\tt same\_generation/2} which
terminates in Prolog.  Second, because answers are sometimes obtained
using program clauses and sometimes using the table, answers may be
returned in an unaccustomed order.

\paragraph*{Tabling Dynamic Predicates}

Dynamic predicates may be tabled just as static predicates, as the
following exercise shows.

\begin{exercise}
For instance, restart XSB and at the prompt type the directive
\begin{verbatim}
         ?- table(dyn_path/2).
\end{verbatim}
and 
\begin{verbatim}
         ?- load_dyn(dyn_examples).
\end{verbatim}
Try the queries to {\tt path/2} of the previous examples.  Note that
it is important to dynamically load {\tt dyn\_examples.P} ---
otherwise the code in the file will be compiled without knowledge of
the tabling declaration.\fillBox
\end{exercise}

In general, as long as the directive {\tt table/1} is executed before
asserting (or dynamically loading) the predicates referred to in the
directive, any dynamic predicate can be tabled.

\index{termination}
\paragraph*{Letting XSB Decide What to Table}
Other tabling declarations are also provided.  Often it is tedious to
decide which predicates must be tabled.  To address this, XSB can
automatically table predicates in files.  The declaration {\tt
  auto\_table}\index{declarations!\texttt{auto\_table}} chooses predicates to table
to assist in termination, while {\tt
  suppl\_table}\index{declarations!\texttt{suppl\_table}} chooses predicates to
table to optimize data-oriented queries.  Both are explained in
\refsec{sec:CompilerOptions}.~\footnote{The reader may have noted that
  {\tt table/1}, is referred to as a \emph{directive}, while {\tt
    auto\_table/0} and {\tt suppl\_table/0} were referred to as
  \emph{declarations}.  The difference is that at the command line,
  user can execute a directive but not a compiler declaration.}.

%--------------------------------------------------------------------

\subsection{Call Variance vs. Call Subsumption}
\label{sec:SimilarityMeasures}
\index{tabling!similarity measures}
\index{tabling!call subsumption}
\index{tabling!answer subsumption}
\index{tabling!call variance}

The above description gives a general characterization of tabled
evaluation for definite programs but glosses over certain details.  In
particular, we have not specified the criteria for 
\begin{itemize}
\item {\em Call Similarity} -- whereby a newly issued subgoal $S$ is
  determined to be ``sufficiently similar'' to a tabled subgoal
  $S_{tab}$ so that $S$ can use the answers from the table of
  $S_{tab}$ rather than re-deriving its own answers.  In the first
  case where $S$ uses answers of a tabled subgoal it is termed a
  consumer; in the second case when $S$ produces its own answers it is
  called a generator or producer.
%
\item {\em Answer Similarity} -- whereby a derived answer to a tabled
  subgoal is determined to contain information similar to that already
  in the set of answers for that subgoal.
\end{itemize}
Different measures of similarity are possible.  XSB's engine supports
two measures for call similarity: variance and subsumption.  XSB's
engine supports a variance-based measure for answer similarity, but
allows users to program other measures in certain cases.  We discuss
call similarity here, but defer the discussion of answer similarity
until Section~\ref{sec:table-aggregation}.

% - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -

\paragraph{Determining Call Similarity via Variance}
\index{tabling!call variance} 
%
By default, XSB determines that a subgoal $S$ is similar to a tabled
subgoal $S_{tab}$ if $S$ is a {\em variant} of $S_{tab}$, that is if
$S$ and $S_{tab}$ are identical up to variable
renaming~\footnote{Formally, $S$ and $S_{tab}$ are variants if they
  have an mgu $\theta$ such that the domain and range of $\theta1$
  consists only of variables.}.  As an example {\tt p(X,Y,X)} is a
variant of {\tt p(A,B,A)}, but not of {\tt p(X,Y,Y)}, or {\tt
  p(X,Y,Z)}.  Under variance-based call similarity, or {\em call
  variance}, when a tabled subgoal $S$ is encountered, a search for a
table entry containing a variant subgoal $S_{tab}$ is performed.
Notice that if $S_{tab}$ exists, then \emph{all} of its answers are
also answers to $S$, and therefore will be resolved against it.  Call
variance was used in the original formulation of SLG resolution
\cite{ChWa96} for the evaluation of normal logic programs according to
the well-founded semantics and interacts well with many of Prolog's
extra-logical constructs.


\comment{ Likewise, when an answer $A$ is derived for a producing
  subgoal $S$, $A$ is inserted into the answer set $\cA$ of $S$ if and
  only if $A$ does not already exist in $\cA$~---~that is, if there is
  no variant of $A$ already present in $\cA$\@.  The insertion of $A$,
  therefore, leads to the return of $A$ to consumers of $S$\@.
  However, the return of only the most general answers to a consumer,
  referred to as \emph{answer subsumption}, can be flexibly programmed
  as discussed in Section~{\ref{sec:table-aggregation}} }

% - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -

\paragraph{Determining Call Similarity via Subsumption}
\index{tabling!call subsumption}

Call similarity can also be based on {\em call subsumption}.  A term
$T_1$ \emph{subsumes} a term $T_2$ if $T_2$ is more specific than
$T_1$~\footnote{Formally, $T_1$ subsumes $T_2$ if there is a
  substitution $\theta$ whose domain consists only of variables from
  $T_1$ such that $T_1\theta = T_2$.}.  Furthermore, we say that $T_1$
\emph{properly subsumes} $T_2$ if $T_2$ subsumes $T_1$, but is not a
variant of $T_1$.  Under call subsumption, when a tabled subgoal $S$
is encountered, a search is performed for a table entry containing a
{\em subsuming} subgoal $S_{tab}$\@.  Notice that, if such an entry
exists, then its answer set $\cA$ logically contains all the solutions
to satisfy $C$\@.  The subset of answers $\cA' \subseteq \cA$ which
unify with $C$ are said to be \emph{relevant to} $C$\@.  

Notice that call subsumption permits greater reuse of computed
results, thus avoiding even more program resolution, and thereby can
lead to time and space performances superior to call variance.  In
addition, beginning with Version 3.2, call-subsumption based tabling
fully supports well-founded negation under the default local
scheduling strategy.  However, there are downsides to this paradigm.
First of all, subsumptively tabled predicates do not interact well
with certain Prolog constructs with which variant-tabled predicates
can (see Example~\ref{example:sub-fail} below).  Second, call
subsumption does not yet support calls with tabled attributed
variables or answer subsumption~\footnote{Beginning with Version 3.2,
  XSB supports attributed variables in answers under call subsumption,
  although not in calls.}.
\index{attributed variables}
\index{tabling!attributed variables}

\index{tabling!call subsumption}
\begin{example} \rm 
The terms $T_1$: {\tt p(f(Y),X,1)} and $T_2$:~{\tt p(f(Z),U,1)} are
\emph{variants} as one can be made to look like the other by a
renaming of the variables.  Therefore, each \emph{subsumes} the other. \\
\noindent The term $t_3$: {\tt p(f(Y),X,1)} \emph{subsumes} the term
$t_4$:~{\tt p(f(Z),Z,1)}.  However, they are \emph{not variants}.  Hence
$t_3$ \emph{properly subsumes}~$t_4$.\fillBox
\end{example}

The above examples show how a variant-based tabled evaluation can
reduce certain redundant subcomputations over SLD\@.  However, even
more redundancy can be eliminated, as the following example shows.

\begin{exercise} \label{ex:VarVsSub} \rm
Begin by abolishing all tables in XSB, and then type the following query
\begin{verbatim}
         ?- abolish_all_tables.
         ?- path(X,Y), fail.
\end{verbatim}
Notice that only a single table entry is created during the evaluation
of this query.  You can check that this is the case by invoking the
following query
\begin{verbatim}
         ?- get_calls_for_table(path/2,Call).
\end{verbatim}
Now evaluate the query
\begin{verbatim}
         ?- path(1,5), fail.
\end{verbatim}
and again check the subgoals in the table.  Notice that two more have
been added.  Further notice that these new subgoals are
\emph{subsumed} by that of the original entry.  Correspondingly, the
answers derived for these newer subgoals are already present in the
original entry.  You can check the answers contained in a table entry
by invoking \code{get\_returns\_for\_call/2} on a tabled subgoal.  For
example:
\begin{verbatim}
         ?- get_returns_for_call(p(1,_),Answer).
\end{verbatim}
Compare these answers to those of \code{p(X,Y)} and \code{p(1,5)}.
Notice that the same answer can, and in this case does, appear in
multiple table entries.

Now, let's again abolish all the tables and change the evaluation
strategy of \code{path/2} to use subsumption.
\begin{verbatim}
	 ?- abolish_all_tables.
         ?- table path/2 as subsumptive.
\end{verbatim}
And re-perform the first few queries:
\begin{verbatim}
         ?- path(X,Y),fail.
	 ?- get_calls_for_table(path/2,Call).
	 ?- path(1,5).
	 ?- get_calls_for_table(path/2,Call).
\end{verbatim}
Notice that this time the table has not changed!  Only a single entry
is present, that for the original query \code{p(X,Y)}.
\end{exercise}
%
When using call subsumption, XSB is able to recognize a greater range
of ``redundant'' queries and thereby make greater use of previously
computed answers.  The result is that less program resolution is
performed and less redundancy is present in the table.  However,
subsumption is not a panacea.  The elimination of redundant answers
depends upon the presence of a subsuming subgoal in the table when the
call to \code{p(1,5)} is made.  If the order of these queries were
reversed, one would find that the same entries would be present in
this table as the one constructed under variant-based evaluation.

\index{tabling!call subsumption}
\paragraph{Declarations for Call Variance and Call Subsumption}
By default tabled predicate use call variance.  However, call
subsumption can be made the default by giving XSB the \verb|-S| option
at invocation (refer to \refsec{sec:EmuOptions}).  More versatile
constructs are provided by XSB so that the tabling method can be
selected on a \emph{per predicate} basis.  Use of the directive

{\tt table p/n as subsumptive}

or 

{\tt table p/n as variant}

described in \refsec{sec:TablePred:Decl&Mod}, ensures that a tabled
predicate is evaluated using the desired strategy regardless of the
default tabling strategy.
\index{declarations!\texttt{table\ as}}
%----------------------------------------------------------------------

\subsection{Tabling with Interned Ground Terms} 
\label{section:interntabling}
\index{tabling!interned ground terms} \label{section:interned-terms}

XSB supports, on request, a special representation of {\em ground}
terms, known as interned terms (see {\tt intern\_term/2}.)  This
representation is also sometimes known as a ``hash-consing''
representation.  All interned terms are stored in a global area and
each such term is stored only once, with all instances of a given
interned (sub-)term pointing to that one stored representation.  This
can allow for a much more succinct representation of sets of ground
terms that share subterms.  Importantly interned ground terms, in
principle, do not need to be copied into and out of tables.

To take advantage of this possibility, a table must be declared as
{\tt intern}.  As an example of a possible use of this mechanism,
consider a simple DCG that recognizes all strings of a's starting with
a single b:
\begin{verbatim}
:- table bas/2 as intern.

bas --> [b].
bas --> bas, [a].
\end{verbatim}
This predicate must be tabled in order to terminate, since the grammar
is left-recursive.  If we use the usual list representation of an
input string and use variant tabling, every call to {\tt bas/2} and
every return will copy the remaining list into the table, and
recognition will be quadratic.  (For example on my laptop, recognizing
a list of one b followed by 10,000 a's takes about 1.84 seconds, and
20,000 a's about 7.285 seconds.)  If we table {\tt bas/2 as intern},
the initial ground input list will be interned (copied to intern
space) on the first call, and after that every subsequent call of {\tt
bas/2} will be given an interned term, which need not be copied into
(or out of) the table.  In this case the complexity will be linear.
(For example on my laptop, recognizing a list of one b and 1,000,000
a's takes less than a second.)

When a table is declared {\tt as intern}, at the time of a call, all
arguments are automatically interned (with {\tt intern\_term/2})
before the call is looked up in the table, and on return, every answer
is interned before being added to the table.  Copying an interned
subterm into or out of a table requires just a pointer copy, which takes,
of course, constant time.

Because an interned term is treated just like a atom (with no indexing
done on its structure), tabling as intern always uses variant tabling,
and thus cannot be combined with subsumptive tabling.  (However, see
{\tt intern\_termhash/2}, described in Section \ref{interntermhash},
for a way to program this explicitly, using lower-level predicates.)
Also it cannot be combined with answer subsumption tabling.

For more information on tabling as intern, see
\cite{ciclops-2013-interning}.

%----------------------------------------------------------------------


\subsection{Table Scheduling Strategies} \label{section:scheduling}
\index{tabling!scheduling strategies}

Recall that SLD resolution works by selecting a goal from a list of
goals to be proved, and selecting a program clause $C$ to resolve
against that goal.  During resolution of a top level goal $G$, if the
list of unresolved goals becomes empty, $G$ succeeds, while if there
is no program clause to resolve against the selected goal from the
list resolution against $G$ fails.  In Prolog clauses are selected in
the order they are asserted, while literals are selected in a
left-to-right selection strategy.  Other strategies are possible for
SLD, and in fact completeness of SLD for definite programs depends on
a non-fixed literal selection strategy.  This is why Prolog, which has
a fixed literal selection strategy is not complete for definite
programs, even when they have bounded term-depth.

Because tabling uses program clause resolution, the two parameters of
clause selection and literal selection also apply to tabling.  Tabling
makes use of a dynamic literal selection strategy for certain
non-stratified programs (via the delaying mechanism described in
Section~\ref{sec-neg-unstratified}), but uses the same left-to-right
literal selection strategy as Prolog for definite programs.  However,
in tabling there is also a choice of when to return derived answers to
subgoals that consume these answers.  While full discussion of
scheduling strategies for tabling is not covered here
(see~\cite{JFLP-Scheduling}) we discuss two scheduling strategies
that have been implemented for XSB \version~\footnote{Many other
  scheduling strategies are possible.  For instance, \cite{FrSW97}
  describes a tabling strategy implemented for the SLG-WAM that
  emulates magic sets under semi-naive evaluation.  This scheduling
  strategy, however, is not available in \version{} of XSB.}.

\begin{itemize}

\index{strongly connected components (SCCs)}
\item {\em Local Scheduling} Local Scheduling depends on the notion of
  a {\em subgoal dependency graph}.  For the state of a tabled
  evaluation, a non-completed tabled subgoal $S_1$ directly depends on
  a non-completed subgoal $S_2$ when $S_2$ is in the SLG tree for
  $S_1$ -- that is when $S_2$ is called by $S_1$ without any
  intervening tabled predicate.  The edges of the subgoal dependency
  graph are then these direct dependency relations, so that the
  subgoal dependency graph is directed.  As mentioned, the subgoal
  dependency graph reflects a given state of a tabled evaluation and
  so may changed as the evaluation proceeds, as new tabled subgoals
  are encountered, or encountered in different contexts, as tables
  complete, and so on.  As with any directed graph, the subgoal
  dependency graph can be divided up into strongly connected
  components, consisting of tabled subgoals that depend on one
  another.  Local scheduling then fully evaluates each maximal SCC (a
  SCC that does not depend on another SCC) before returning answers to
  any subgoal outside of the SCC~\footnote{XSB's implementation
    maintains a slight over-approximation of SCCs -- see
    \cite{JFLP-Scheduling}.}.

\item {\em Batched Scheduling} Unlike Local Scheduling, Batched
  Scheduling allows answers to be returned outside of a maximal SCC as
  they are derived, and thus resembles Prolog's tuple at a time
  scheduling.  
\end{itemize}

Both Local and Batched Scheduling have their advantages, and we list
points of comparison.

\begin{itemize}

\item {\em Time for left recursion} Batched Scheduling is somewhat
  faster than Local Scheduling for left recursion as Local Scheduling
  imposes overhead to prevent answers from being returned outside of
  a maximal SCC.  

\item {\em Time to first answer}  Because Batched Scheduling returns
  answers out of an SCC eagerly, it is faster to derive the first
  answer to a tabled predicate.

\item {\em Stack space} Local evaluation generally requires less space
  than batched evaluation as it fully explores a maximal SCC,
  completes the SCC's subgoals, reclaims space, and then moves on to a
  new SCC.  

\item {\em Integration with cuts} As discussed in
  Exercise~\ref{ex:nocut} and throughout Section~\ref{sec:cuts}, Local
  Scheduling integrates better with cuts, although this is partly
  because tabled subgoals may be fully evaluated before the cut takes
  effect. 

\item {\em Efficiency for call subsumption} Because Local Evaluation
  completes tables earlier than Batched Evaluation it may be faster
  for some uses of call subsumption, as subsumed calls can make use of
  completed subsuming tables.

\item {\em Negation and tabled aggregation} As will be shown below,
  Local Scheduling is superior for tabled aggregation as only optimal
  answers are returned out of a maximal SCC.  Local Scheduling also
  can be more efficient for non-stratified negation as it may allow
  delayed answers that are later simplified away to avoid being
  propagated.
\end{itemize}

On the whole, advantages of Local Scheduling outweigh the advantages of
Batched Scheduling, and for this reason Local Scheduling is the
default scheduling strategy for \version{} of XSB.  XSB can be
configured to use batched scheduling via the configuration option {\tt
  --enable-batched-scheduling} and remaking XSB\@.  This will not
affect the default version of XSB, which will also remain available.

%--------------------------------------------------------------------

\subsection{Interaction Between Prolog Constructs and Tabling}

Tabling integrates well with most non-pure aspects of Prolog.
Predicates with side-effects like {\tt read/1} and {\tt write/1} can
be used freely in tabled predicates as long as it is remembered that
only the first call to a goal will execute program clauses while the
rest will look up answers from a table.  However, other extra-logical
constructs like the cut (\texttt{!}) pose greater difficulties.
Tabling with call subsumption is also theoretically precluded from
correct interaction with certain meta-logical predicates.

\paragraph{Cuts and Tabling} \label{sec:cuts}
\index{tabling!cuts}

The semantics for cuts in Prolog is largely operational, and is
usually defined based on an ordered traversal of an SLD search tree.
Tabling, of course, has a different operational semantics than Prolog
-- it uses SLG trees rather than SLD trees, for instance -- so it is
not surprising that the interaction of tabling with cuts is
operational.  In Prolog, the semantics for a cut can be expressed in
the following manner: a cut executed in the body of a predicate $P$
frames from the top (youngest end) of the choice point stack down to
and including the call for $P$.  In XSB {\em a cut is allowed to
  succeed as long as it does not cut over a choice point for a
  non-completed tabled subgoal, otherwise, the computation aborts}.
This means, among other matters, that the validity of a cut depends on
the {\em scheduling strategy} used for tabling, that is on the
strategy used to determine when an answer is to be returned to a
consuming subgoal.  Scheduling strategy was discussed
Section~\ref{section:scheduling}: for now, we assume that XSB's
default local scheduling is used in the examples for cuts.

\begin{exercise} \label{ex:nocut}
Consider the program
\begin{verbatim}
:- table cut_p/1, cut_q/1, cut_r/0, cut_s/0.

cut_p(X) :- cut_q(X), cut_r.
cut_r :- cut_s.
cut_s :- cut_q(_).
cut_q(1).   cut_q(2).
\end{verbatim}
What solutions are derived for the goal {\tt ?- cut\_p(X)}\@?  Suppose
that {\tt cut\_p/1} were rewritten as
\begin{verbatim}
cut_p(X) :- cut_q(X), once(cut_r).
\end{verbatim}
How should this cut over a table affect the answers generated for {\tt
cut\_p/1}?  What happens if you rewrite {\tt cut\_p/1} in this way and
compile it in XSB?\fillBox
\end{exercise}

In Exercise \ref{ex:nocut}, {\tt cut\_p(1)} and {\tt cut\_p(2)} should
both be true.  Thus, the cut in the literal {\tt once(cut\_r)} must
not inadvertently cut away solutions that are demanded by {\tt
  cut\_p/1}.  In the default local scheduling of XSB \version{} tabled
subgoals are fully evaluated whenever possible before returning any of
their answers.  Thus the first call {\tt cut\_q(X)} in the body of the
clause for {\tt cut\_p/1} is fully evaluated before proceeding to the
goal {\tt once(cut\_r)}.  Because of this any choice points for {\tt
  cut\_q(X)} are to a completed table.  For other scheduling
strategies, such as batched scheduling, non-completed choice points
for {\tt cut\_p/1} may be present on the choice point stack so that the
cut would be disallowed.  In addition, it is also possible to
construct examples where a cut is allowed if call variance is used,
but not if call subsumption is used.

\begin{example}
A further example of using cuts in a tabled predicate is a tabled
meta-interpreter.
\begin{verbatim}
:- table demo/1.

demo(true).
demo((A,B)) :- !, demo(A), demo(B).
demo(C) :- call(C).
\end{verbatim}
More elaborate tabled meta-interpreters can be extremely useful, for
instance to implement various extensions of definite or normal
programs.\fillBox
\end{example}

In XSB's compilation, the cut above is compiled so that it is valid to
use with either local or batched (a non-default) evaluation.  An
example of a cut that is valid neither in batched nor in local
evaluation is as follows.

\begin{example} \label{ex:cutTable}
Consider the program
\begin{verbatim}
:- table cut_a/1, cut_b/1.

cut_a(X):- cut_b(X).
cut_a(a1).

cut_b(X):- cut_a(X).
cut_b(b1).
\end{verbatim}
For this program the goal {\tt ?- cut\_a(X)} produces two answers, as
expected: {\tt a1} and {\tt b1}.  However, replacing the first class
of the above program with 
\begin{verbatim}
cut_a(X):- once(cut_b(X)).
\end{verbatim}
will abort both in batched or in local evaluation.
\fillBox
\end{example}

To summarize, the behavior of cuts with tables depends on dynamic
operational properties, and we have seen examples of programs in which
a cut is valid in both local and batched scheduling, in local but not
batched scheduling, and in neither batched nor local scheduling.  In
general, any program and goal that allows cuts in batched scheduling
will allow them in local scheduling as well, and there are programs
for which cuts are allowed in local scheduling but not in batched.

Finally, we note that in \version{} of XSB a ``cut'' over tables
implicitly occurs when the user makes a call to a tabled predicate
from the interpreter level, but does not generate all solutions.  This
commonly occurs in batched scheduling, but can also occur in local
scheduling if an exception occurs.  In such a case, the user will see
the warning {\tt "Removing incomplete tables..."} appear.  Any
complete tables will not be removed.  They can be abolished by using
one of XSB's predicates for abolishing tables.

\paragraph{Call Subsumption and Meta-Logical Predicates}
\index{tabling!call subsumption!interaction with meta-logical predicates}

Meta-logical predicates like {\tt var/1} can be used to filter the
choices made during an evaluation.  However, this is dangerous when
used in conjunction with call subsumption, since call subsumption
assumes that if a specific relation holds~---~e.g.,
\texttt{p(a)}~---~then a more general query~---~e.g.,
\texttt{p(X)}~---~will also hold.

\begin{example}\label{example:sub-fail}
Consider the following simple program
\begin{verbatim}
        p(X) :- var(X), X = a.
\end{verbatim}
to which the queries
\begin{verbatim}
        ?- p(X).
        ?- p(a).
\end{verbatim}
are posed.  Let us compare the outcome of these queries when
\code{p/1} is (1)~a Prolog predicate, (2)~a variant-tabled predicate,
and (3)~a subsumptive-tabled predicate.

Both Prolog and variant-based tabling yield the same solutions:
\code{X = a}\, and\, \code{no}, respectively.  Under call subsumption,
the query \verb|?-|$\;$\code{p(X).} likewise results in the solution
\code{X = a}.  However, the query \verb|?-|$\;$\code{p(a).}  is
subsumed by the tabled subgoal \code{p(X)}~---~which was entered into
the table when that query was issued~---~resulting in the incorrect
answer \code{yes}.\fillBox
\end{example}
%
As this example shows, \emph{incorrect answers} can result from using
meta-logical with subsumptive predicates in this way.

%--------------------------------------------------------------------

\subsection{Potential Pitfalls in Tabling}
\label{sec:TablingPitfalls}

\paragraph{Over-Tabling}
While the judicious use of tabling can make some programs faster, its
indiscriminate use can make other programs slower.  Naively tabling
{\tt append/3}
\begin{center}
\begin{minipage}{3.5in}
\begin{verbatim}
append([],L,L).
append([H|T],L,[H|T1]) :- append(T,L,T1).
\end{verbatim}						       
\end{minipage}
\end{center}
is one such example.  Doing so can, in the worst case, copy $N$
sublists of the first and third arguments into the table, transforming
a linear algorithm into a quadratic one.

\begin{exercise} \label{ex:append}
If you need convincing that tabling can sometimes slow a query down,
type the query:
\begin{verbatim}
         ?- genlist(1000,L), prolog_append(L,[a],Out).
\end{verbatim}
and then type the query
\begin{verbatim}
         ?- genlist(1000,L), table_append(L,[a],Out).
\end{verbatim}
{\tt append/3} is a particularly bad predicate to table.  Type the query
\begin{verbatim}
         ?- table_append(L,[a],Out).
\end{verbatim}
leaving off the call to {\tt genlist/2}, and backtrack through a few answers.
Will {\tt table\_append/3} ever succeed for this predicate?  Why not?

Suppose DCG predicates (Section \ref{DCGs}) are defined to be tabled.
How is this similar to tabling append?\fillBox
\end{exercise}
%
We note that XSB has special mechanisms for handling tabled DCGs.  See
Section \ref{DCGs} for details.

\paragraph{Tabled Predicates and Tracing}
Another issue to be aware of when using tabling in XSB is tracing.
XSB's tracer is a standard 4-port tracer that interacts with the
engine at each call, exit, redo, and failure of a predicate (see
Chapter \ref{debugging}).  When tabled predicates are traced, these
events may occur in unexpected ways, as the following example shows.

\begin{exercise} \label{ex:scc}

Consider a tabled evaluation when the query {\tt ?- a(0,X)} is given
to the following program
\begin{verbatim}
:- table mut_ret_a/2, mut_ret_b/2.
mut_ret_a(X,Y) :- mut_ret_d(X,Y).
mut_ret_a(X,Y) :- mut_ret_b(X,Z),mut_ret_c(Z,Y).

mut_ret_b(X,Y) :- mut_ret_c(X,Y).
mut_ret_b(X,Y) :- mut_ret_a(X,Z),mut_ret_d(Z,Y).

mut_ret_c(2,2).      mut_ret_c(3,3).

mut_ret_d(0,1).	     mut_ret_d(1,2).     mut_ret_d(2,3).
\end{verbatim}
{\tt mut\_ret\_a(0,1)} can be derived immediately from the first
clause of {\tt mut\_ret\_a/2}.  All other answers to the query depend
on answers to the subgoal {\tt mut\_ret\_b(0,X)} which arises in the
evaluation of the second clause of {\tt mut\_ret\_a/2}.  Each answer
to {\tt mut\_ret\_b(0,X)} in turn depends on an answer to {\tt
mut\_ret\_a(0,X)}, so that the evaluation switches back and forth
between deriving answers for {\tt mut\_ret\_a(0,X)} and {\tt
mut\_ret\_b(0,X)}.

Try tracing this evaluation, using creep and skip.  Do you find the
behavior intuitive or not?\fillBox
\end{exercise}

%=====================================================================

\section{Normal Programs}
\index{tabling!negation}
Normal programs extend definite programs to include default negation,
which posits a fact as false if all attempts to prove it fail.  As
shown in Example \ref{ex:Russell}, which presented one of Russell's
paradoxes as a logic program, the addition of default negation allows
logic programs to express contradictions.  As a result, some
assertions, such as {\tt shaves(barber,barber)} may be undefined,
although other facts, such as {\tt shaves(barber,mayor)} may be true.
Formally, the meaning of normal programs may be given using the {\em
well-founded semantics} and it is this semantics that XSB adopts for
negation (we note that in \version{} the well-founded semantics is
implemented only for variant-based tabling).

\subsection{Stratified Normal Programs}
\index{negation!stratified}

Before considering the full well-founded semantics, we discuss how XSB
can be used to evaluate programs with {\em stratified negation}.
Intuitively, a program uses stratified negation whenever there is no
recursion through negation.  Indeed, most programmers, most of the
time, use stratified negation.  
%Refining this intuition can lead to an
%array of stratification classes which we will discuss in Section
%\ref{sec:nonstrat}.

\begin{exercise} \label{ex:win1}
The program
\begin{verbatim}
         win(X):- move(X,Y),tnot(win(Y)).
\end{verbatim}
is stratified when the {\tt move/2} relation is a binary tree.  To see
this, load the files \textup{\texttt{tree1k.P}} and
\textup{\texttt{table\_examples.P}} from the directory
\textup{\texttt{\$XSB\_DIR/examples}} and type the query
%
\begin{verbatim}
         ?- win(1).
\end{verbatim}
{\tt win(1)} calls {\tt win(2)} through negation, {\tt win(2)} calls
{\tt win(4)} through negation, and so on, but no subgoal ever calls
itself recursively through negation.
\end{exercise}

The previous example of {\tt win/1} over a binary tree is a simple
instance of a stratified program, but it does not even require
tabling.  A more complex example is presented below.

\begin{exercise} \label{ex:lrd}
Consider the query {\tt ?- lrd\_s} to the following program
\begin{verbatim}
lrd_p:- lrd_q,tnot(lrd_r),tnot(lrd_s).
lrd_q:- lrd_r,tnot(lrd_p).
lrd_r:- lrd_p,tnot(lrd_q).
lrd_s:- tnot(lrd_p),tnot(lrd_q),tnot(lrd_r). 
\end{verbatim}
Should {\tt lrd\_s} be true or false?  Try it in XSB\@.  Using the
intuitive definition of ``stratified'' as not using recursion through
negation, is this program stratified?  Would the program still be
stratified if the order of the literals in the body of clauses for
{\tt lrd\_p}, {\tt lrd\_q}, or {\tt lrd\_r} were changed?
\end{exercise}

The rules for {\tt p}, {\tt q} and {\tt r} are involved in a positive
loop, and no answers are ever produced.  Each of these atoms can be
failed, thereby proving {\tt s}.  Exercise \ref{ex:lrd} thus
illustrates an instance of how tabling differs from Prolog in
executing stratified programs since Prolog would not fail finitely for
this program~\footnote{\LRD stratification may be reminiscent of the
  Subgoal Dependency Graphs of Section~\ref{section:scheduling} but
  differ in several respects, most notably in that stratification
  considers only cycles through negative dependencies.}.

\paragraph*{Completely Evaluated Subgoals}
\index{tabling!complete evaluation}

Knowing when a subgoal is completely evaluated can be useful when
programming with tabling.  Simply put, a subgoal $S$ is {\em
  completely evaluated} if an evaluation can produce no more answers
for $S$\@.  The computational strategy of XSB makes heavy use of
complete evaluation so that understanding this concept and its
implications can be of great help to a programmer.

Consider a simple approach to incorporating negation into tabling.
Each time a negative goal is called, a separate table is opened for
the negative call.  This evaluation of the call is carried on to
termination.  If the evaluation terminates, its answers, if any, are
used to determine the success of failure of the calling goal.  This
general mechanism underlies early formulations for tabling stratified
programs \cite{KeTo88,Seki89}.  Of course this method may not be
efficient.  Every time a new negative goal is called, a new table must
be started, and run to termination.  We would like to reuse information
already derived from the computation to answer a new query, if at all
possible --- just as with definite programs.

\index{tabled subgoals!incomplete}
\index{tabled subgoals!complete}
XSB addresses this problem by keeping track of the {\em state} of each
subgoal in the table.  A call can have a state of {\em complete}, {\em
incomplete} or {\em not\_yet\_called}.  
%The value $not\_yet\_called$
%means that there is in fact no table entry.  
Calls that do have table entries may be either $complete$ or
$incomplete$.  A subgoal in a table is marked $complete$ only after it
is determined to be completely evaluated; otherwise the subgoal is
$incomplete$.  If a tabled subgoal is not present in the table, it is
termed {\em not\_yet\_called}.  XSB contains predicates that allow a
user to examine the state of a given table (Section
\ref{sec:TablingPredicates}).

\index{tabling!early completion of subgoals} There are in fact two
ways that a tabled subgoal $S$ can be determined to be completely
evaluated.  If $S$ is part of an SCC $\cS$, (a mutually recursive
component), then $S$ can be completed once it is ensure that all
resolution steps have been done to all subgoals in $\cS$.  Otherwise,
if there is a derivation of an answer that is identical to $S$, $S$
can be completed before the rest of the subgoals in $\cS$ since
further evaluation of $S$ itself will not produce useful information.
In this case, we sometimes say that $S$ is {\em early
  completed}.\footnote{The use of sound early completion based on a
  maximal number of answers per tabled subgoal can also be declared by
  the user: see Section~\ref{sec:tabling-termination}.}

Using these concepts, we can overview how tabled negation is evaluated
for stratified programs.  If a literal {\tt tnot(S)} is called, where
{\tt S} is a tabled subgoal, the evaluation checks the state of {\tt
S}.  If {\tt S} is $complete$ the engine simply determines whether the
table contains an answer for {\tt S}.  Otherwise the engine $suspends$
the computation path leading to {\tt tnot(S)} until {\tt S} is
completed (and calls {\tt S} if necessary).  Whenever a suspended
subgoal {\tt tnot(S)} is completed with no answers, the engine resumes
the evaluation at the point where it had been suspended.  We note that
because of this behavior, tracing programs that heavily use negation
may produce behavior unexpected by the user.



\paragraph*{{\tt tnot/1} vs. \not }
\predrefindex{tnot/1}
\predrefindex{$\backslash$\texttt{+/1}}
Subject to some semantic restrictions, an XSB programmer can intermix
the use of tabled negation ({\tt tnot/1}) with Prolog's negation
(\not, or equivalently {\tt fail\_if/1} or {\tt not/1}).  These
restrictions are discussed in detail below --- for now we focus on
differences in behavior or these two predicates in stratified
programs.  Recall that ${\tt '\backslash+'(S)}$ calls $S$ and if $S$
has a solution, Prolog executes a cut over the subtree created by
${\tt '\backslash+'(S)}$, and fails.  {\tt tnot/1} on the other hand,
does not execute a cut, so that all subgoals in the computation path
begun by the negative call will be completely evaluated.  The major
reason for not executing the cut is to ensure that XSB evaluates
ground queries to Datalog programs with negation with polynomial data
complexity.  As seen \cite{ChWa96}, this property cannot be preserved
if negation ``cuts'' over tables.

There are other small differences between {\tt tnot/1} and \not 
\ illustrated in the following exercise.

\begin{exercise}
In general, making a call to non-ground negative subgoal in Prolog may
be unsound (cf. \cite{Lloy84}), but the following program illustrates
a case in which non-ground negation is sound.
\begin{verbatim}
ngr_p:- \+ ngr_p(_).
ngr_p(a).
\end{verbatim}
One tabled analog is 
\begin{verbatim}
:- table ngr_tp/1.
ngr_tp(a).

ngr_tp:- tnot(ngr_tp(_)).
\end{verbatim}
\version{} of XSB will flounder on the call to {\tt ngr\_tp}, but not
on the call to {\tt ngr\_p/0}.  On the other hand if {\tt not\_exists/1}
is used
\begin{verbatim}
ngr_skp:- not_exists(ngr_tp(_)).
\end{verbatim}
the non-ground semantics is allowed.  
\end{exercise}

{\tt not\_exists/1} works by
asserting a new tabled subgoal, abstractly 
\begin{verbatim}
:- table '_$ngr_tp'
'_$skolem_ngr_tp' :- ngr_tp(_).
\end{verbatim}
to avoid the problem with variables.  In addition, since {\tt
  not\_exists/1} creates a new tabled predicate, it can be used to call
non-tabled predicates as well, ensuring tabling.

The description of {\tt tnot/1} in Section \ref{sec:control} describes
other small differences between \not \ and {\tt tnot/1} as implemented
in XSB\@. Before leaving the subject of stratification, we note that the
concepts of stratification also underly XSB's evaluation of tabled
findall: {\tt tfindall/3}.  Here, the idea is that a program is
stratified if it contains no loop through tabled findall (See the
description of predicate {\tt tfindall/3} on
page~\pageref{tfindall/3}).

\subsection{Non-stratified Programs}
\label{sec-neg-unstratified}
\index{negation!unstratified}

As discussed above, in stratified programs, facts are either true or
false, while in non-stratified programs facts may also be undefined.
XSB represents undefined facts as {\em conditional answers}.

\paragraph*{Conditional Answers} \label{sec:conditional-answers}
\index{tabling!conditional answers}

\begin{exercise}
Consider the behavior of the {\tt win/1} predicate from Exercise
\ref{ex:win1}.
\begin{verbatim}
         win(X):- move(X,Y),tnot(win(Y)).
\end{verbatim}
when the when the {\tt move/2} relation is a cycle.  Load the file
{\tt \verb|$XSB_DIR/examples|cycle1k.P} into XSB and again type the
query {\tt ?- win(1)}.  Does the query succeed?  Try {\tt
tnot(win(1))}.

Now query the table with the standard XSB predicate {\tt
get\_residual/2}, e.g. {\tt ?- get\_residual(win(1),X)}.  Can you guess
what is happening with this non-stratified program?
\end{exercise}

The predicate {\tt get\_residual/2} (Section \ref{sec:TablingPredicates})
unifies its first argument with a tabled subgoal and its second
argument with the (possibly empty) delay list of that subgoal.  The
truth of the subgoal is taken to be conditional on the truth of the
elements in the delay list.  Thus {\tt win(1)} is conditional on {\tt
tnot(win(2))}, {\tt win(2)} in {\tt tnot(win(3))} and so on until {\tt
win(1023)} which is conditional on {\tt win(1)}.

From the perspective of the well-founded semantics, {\tt win(1)} is
undefined.  Informally, true answers in the well-founded semantics are
those that have a (tabled) derivation.  False answers are those for
which all possible derivations fail --- either finitely as in Prolog
or by failing positive loops.  {\tt win(1)} fits in neither of these
cases -- there is no proof of {\tt win(1)}, yet it does not fail in
the sense given above and is thus undefined.

However this explanation does not account for why undefined answers
should be represented as conditional answers, or why a query with a
conditional answer {\em and} its negation should both succeed.  These
features arise from the proof strategy of XSB, which we now examine in
more detail.

\begin{exercise} \label{ex:simpl}
Consider the program
\begin{verbatim}
:- table simpl_p/1,simpl_r/0,simpl_s/0.
simpl_p(X):- tnot(simpl_s).

simpl_s:- tnot(simpl_r).
simpl_s:- simpl_p(X).

simpl_r:- tnot(simpl_s),simpl_r.
\end{verbatim}
Try the query {\tt ?- simpl\_p(X)}.  If you have a copy of XSB defined
using Batched Scheduling load the examples program and query {\tt ?-
  simpl\_p(X)} -- be sure to backtrack through all possible answers.
Now try the query again.  What could possibly account for the
difference in behavior between Local and Batched Scheduling?
\end{exercise}

At this point, it is worthwhile to examine closely the evaluation of
the program in Exercise \ref{ex:simpl}.  The query {\tt simpl\_p(X)}
calls {\tt simpl\_s} and {\tt simpl\_r} and executes the portion of
the program shown below in bold:
\begin{center}
\begin{tabular}{l}
{\bf simpl\_p(X):- tnot(simpl\_s).} \\
\\
{\bf simpl\_s:- tnot(simpl\_r).} \\
{\bf simpl\_s:- simpl\_p(X).} \\
\\
{\bf simpl\_r:- tnot(simpl\_s)},{\it simpl\_r.}
\end{tabular}
\end{center}
Based on evaluating only the bold literals, the three atoms are all
undefined since they are neither proved true, nor fail.  However if
the evaluation could only look at the literal in italics, {\em
  simpl\_r}, it would discover that {\em simpl\_r} is involved in a
positive loop and, since there is only one clause for {\em simpl\_r},
the evaluation could conclude that the atom was false.  This is
exactly what XSB does, it {\em delays} the evaluation of {\tt
  tnot(simpl\_s)} in the clause for {\tt simpl\_r} and looks ahead to
the next literal in the body of that clause.  This action of looking
ahead of a negative literal is called {\em delaying}.  A delayed
literal is moved into the {\em delay list} of a current path of
computation.  Whenever an answer is derived, the delay list of the
current path of computation is copied into the table.  If the delay
list is empty, the answer is unconditional; otherwise it is
conditional.  Of course, for definite programs any answers will be
unconditional --- we therefore omitted delay lists when discussing
such programs.

In the above program, delaying occurs for the negative literals in
clauses for {\tt simpl\_p(X)}, {\tt simpl\_s}, and {\tt simpl\_r}.
In the first two cases, conditional answers can be derived, while in
the third, {\tt simpl\_r} will fail as mentioned above.  Delayed
literals eventually become evaluated through {\em simplification}.
Consider an answer of the form 
\begin{verbatim}
simpl_p(X):- tnot(simpl_s)|
\end{verbatim}
where the {\tt |} is used to represent the end of the delay list.  If,
after the answer is copied into the table, {\tt simpl\_s} turns out to
be false, (after being initially delayed), the answer can become
unconditional.  If {\tt simpl\_s} turns out to be true, the answer
should be removed, it is false.

In fact, it is this last case that occurs in Exercise \ref{ex:simpl}.
The answer
\begin{verbatim}
simpl_p(X):- tnot(simpl_s)|
\end{verbatim}
is derived, and returned to the user (XSB does not currently print out
the delay list).  The answer is then removed through simplification so
that when the query is re-executed, the answer does not appear.

We will examine in detail how to alter the XSB interface so that
evaluation of the well-founded semantics need not be confusing.  It is
worthwhile to note that the behavior just described is uncommon.

\version\ of XSB handles dynamically stratified programs through
delaying negative literals when it becomes necessary to look to their
right in a clause, and then simplifying away the delayed literals when
and if their truth value becomes known.  However, to ensure
efficiency, literals are never delayed unless the engine determines
them to not to be stratified under the \LRD\ evaluation method.

\paragraph{When Conditional Answers are Needed} \label{sec:lrd}

A good Prolog programmer uses the order of literals in the body of a
clause to make her program more efficient.  However, as seen in the
previous section, delaying can break the order that literals are
evaluated within the body of a clause.  It then becomes natural to ask
if any guarantees can be made that XSB is not delaying literals
unnecessarily.

Such a guarantee can in fact be made, using the concept of {\em
dynamic stratification} \cite{Przy89d}.  Without going into the
formalism of dynamic stratification, we note that a program is
dynamically stratified if and only if it has a two-valued model.  It
is also known that computation of queries to dynamically
stratified programs is not possible under any fixed strategy for
selecting literals within the body of a clause.  In other words, some
mechanism for breaking the fixed-order literal selection strategy must
be used, such as delaying.

However, by redefining dynamic stratification to use an arbitrary
fixed-order literal selection strategy (such as the left-to-right
strategy of Prolog), a new kind of stratification is characterized,
called {\em Left-to-Right Dynamic Stratification}, or {\em
LRD-stratification}.  \LRD{} is not as powerful as dynamic
stratification, but is more powerful than other fixed-order
stratification methods, and it can be shown that for ground programs,
XSB delays only when programs are not \LRD.  In the language of
\cite{SaSW99} XSB is {\em delay minimal}.

\paragraph{Programming in the Well-founded Semantics}
\index{well-founded semantics}

XSB delays literals for non-\LRD{} programs and later simplifies them
away.  In Local Scheduling, all simplification will be done before the
first answer is returned to the user.  In Batched Scheduling it is
usually better to make a top-level call for a predicate, {\tt p} as
follows:
\begin{verbatim}
?- p,fail ; p.
\end{verbatim}
when the second {\tt p} in this query is called, all simplification on
{\tt p} will have been performed.  However, this query will succeed if
{\tt p} is true {\em or} undefined.

\begin{exercise} \label{ex:true-val}
Write a predicate {\tt wfs\_call(+Tpred,?Val)} such that if {\tt
Tpred} is a ground call to a tabled predicate, {\tt
wfs\_call(+Tpred,?Val)} calls {\tt Tpred} and unifies {\tt Val} with
the truth value of {\tt Tpred} under the well-founded semantics.
{\em Hint: use {\tt get\_residual/2}}.

How would you modify {\tt wfs\_call(?Tpred,?Val)} so that it properly
handled cases in which {\tt Tpred} is non-ground.
\end{exercise}

\paragraph*{Trouble in Paradise: Answer Completion}
\index{tabling!answer completion}

The engine for XSB performs both program clause and answer resolution,
along with delay and simplification.  What it does not do is to
perform an operation called {\em answer completion} which is needed in
certain (pathological?) programs.

\begin{exercise}
Consider the following program:
\begin{verbatim}
:- table ac_p/1,ac_r/0,ac_s/0.
ac_p(X):- ac_p(X).
ac_p(X):- tnot(ac_s).

ac_s:- tnot(ac_r).
ac_s:- ac_p(X).

ac_r:- tnot(ac_s),ac_r.
\end{verbatim}
Using either the predicate from Exercise \ref{ex:true-val} or some
other method, determine the truth value of {\tt ac\_p(X)}.  What
should the value be?  (hint: what is the value of {\tt ac\_s/1}?).
\end{exercise}

For certain programs, XSB will delay a literal (such as {\tt ac\_p(X)}
that it will not be able to later simplify away.  In such a case, an
operation, called {\em answer completion} is needed to remove the
clause
\begin{verbatim}
      ac_p(X):- ac_p(X)|
\end{verbatim}
Without answer completion, XSB may consider some answers to be
undefined rather than false.  It is thus is sound, but not complete
for terminating programs to the well-founded semantics.  Answer
completion is not available for \version{} of XSB, as it is expensive
and the need for answer completion arises rarely in practice.  However
answer completion will be included at some level in future versions of
XSB\@.

\subsection{On Beyond Zebra: Implementing Other Semantics for
Non-stratified Programs} \label{sec:non-strat}
\index{stable models}

The Well-founded semantics is not the only semantics for
non-stratified programs.  XSB can be used to (help) implement other
semantics that lie in one of two classes.  1) Semantics that extend
the well-founded semantics to include new program constructs; or 2)
semantics that contain the well-founded partial model as a submodel.

An example of a semantics of class 1) is (WFSX) \cite{ADP95}, which
adds explicit (or provable) negation to the default negation used by
the Well-founded semantics.  The addition of explicit negation in
WFSX, can be useful for modeling problems in domains such as diagnosis
and hierarchical reasoning, or domains that require updates
\cite{LePe98}, as logic programs.  WFSX is embeddable into the
well-founded semantics; and this embedding gives rise to an XSB
meta-interpreter, or, more efficiently, to the preprocessor described
in Section {\it Extended Logic Programs} in Volume 2.  See
\cite{Swif99a} for an overview of the process of implementing
extensions of the well-founded semantics.

An example of a semantics of class 2) is the stable model semantics.
Every stable model of a program contains the well-founded partial
model as a submodel.  As a result, the XSB can be used to evaluate
stable model semantics through the {\em residual program}, to which we
now turn.

\index{residual program}

\paragraph*{The Residual Program}

Given a program $P$ and query $Q$, the residual program for $Q$ and
$P$ consists of all (conditional and unconditional) answers created in
the complete evaluation of $Q$\@.  

\begin{exercise} \label{ex:pos-delay}
Consider the following program.
\begin{verbatim}
     :- table ppgte_p/0,ppgte_q/0,ppgte_r/0,ppgte_s/0,
              ppgte_t/0,ppgte_u/0,ppgte_v/0.
     ppgte_p:- ppgte_q.          ppgte_p:- ppgte_r.

     ppgte_q:- ppgte_s.          ppgte_r:- ppgte_u.
     ppgte_q:- ppgte_t.          ppgte_r:- ppgte_v.

     ppgte_s:- ppgte_w.          ppgte_u:- undefined.
     ppgte_t:- ppgte_x.          ppgte_v:- undefined.

     ppgte_w:- ppgte(1).         ppgte_x:- ppgte(0).
     ppgte_w:- undefined.        ppgte_x:- undefined.

     ppgte(0).

     :- table undefined/0.
     undefined:- tnot(undefined).
\end{verbatim}
Write a routine that uses {\tt get\_residual/2} to print out the
residual program for the query {\tt ?- ppgte\_p,fail}.  Try altering the
tabling declarations, in particular by making {\tt ppgte\_q/0}, {\tt
ppgte\_r/0}, {\tt ppgte\_s/0} and {\tt ppgte\_t/0} non-tabled.  What
effect does altering the tabling declarations have on the residual
program?
\end{exercise}

When XSB returns a conditional answer to a literal $L$, it does not
propagate the delay list of the conditional answer, but rather delays
$L$ itself, even if $L$ does not occur in a negative loop.  This has
the advantage of ensuring that delayed literals are not propagated
exponentially through conditional answers.

\paragraph*{Stable Models}
\index{negation!stable models}

Stable models are one of the most popular semantics for non-stratified
programs.  The intuition behind the stable model semantics for a
ground program $P$ can be seen as follows.  Each negative literal $not
L$ in $P$ is treated as a special kind of atom called an {\em
assumption}.  To compute the stable model, a guess is made about
whether each assumption is true or false, creating an assumption set,
$A$\@.  Once an assumption set is given, negative literals do not need
to be evaluated as in the well-founded semantics; rather an evaluation
treats a negative literal as an atom that succeeds or fails depending
on whether it is true or false in $A$\@.

\begin{example}
Consider the simple, non-stratified program
\begin{center}
\begin{Prog}
writes\_manual(terry)-$\neg$writes\_manual(kostis),has\_time(terry). \\
writes\_manual(kostis)-$\neg$writes\_manual(terry),has\_time(kostis). \\
has\_time(terry). \\
has\_time(kostis). \\
\end{Prog}
\end{center}
there are two stable models of this program: in one {\tt
writes\_manual(terry)} is true, and in another {\tt
writes\_manual(kostis)} is true.  In the Well-Founded model, neither
of these literals is true.  The residual program for the above program
is
\begin{center}
\begin{Prog}
writes\_manual(terry)-$\neg$writes\_manual(kostis). \\
writes\_manual(kostis)-$\neg$writes\_manual(terry). \\
has\_time(terry). \\
has\_time(kostis). \\
\end{Prog}
\end{center}
\end{example}

Computing stable models is an intractable problem, meaning that any
algorithm to evaluate stable models may have to fall back on
generating possible assumption sets, in pathological cases.  For a
ground program, if it is ensured that residual clauses are produced
for {\em all} atoms, using the residual program may bring a
performance gain since the search space of algorithms to compute
stable models will be correspondingly reduced.  In fact, by using XSB
in conjunction with a Stable Model generator, Smodels \cite{NiSi97},
an efficient system has been devised for model checking of concurrent
systems that is 10-20 times faster than competing systems
\cite{LiRS98}.  In addition, using the XASP package (see the separate
manual, \cite{CaSW02a} in XSB's packages directory) a consistency
checker for description logics has also been created \cite{Swif04}.

%----------------------------------------------------------------------

\section{Answer Subsumption}  \label{sec:table-aggregation}
\index{tabling!answer subsumption}

%
By default XSB adds an answer $A$ to a table $T$ only if $A$ is not a
variant of some other answer already in $T$, a technique termed {\em
  answer variance}.  While answer variance is sufficient to allow
tabling to compute the well-founded semantics and to terminate for
programs with bounded term-depth, other choices of when and how to add
an answer can be made.  Using {\em partial order answer subsumption},
$A$ would be added to $T$ only if $A$ is maximal with respect to other
answers in $T$ according to a given partial order $>_O$. Furthermore
if $A$ is added, any answers in $T$ that $A$ subsumes (i.e., is
greater than in $>_O$) are deleted.  When using {\em lattice answer
  subsumption}, $A$ itself may not be added to $T$, rather the join is
taken of $A$ and another answer $A'$ in $T$, with $A'$ being deleted.
Despite its conceptual simplicity, answer subsumption can be a
powerful tool.  Partial order answer subsumption allows a table to
retain only answers that are maximal according to a metric or to a
preference relation; lattice answer subsumption can form the basis of
multi-valued logics, quantitative logics, and of abstract
interpretations for programs and process logics.

Dynamic predicates can be declared to use answer subsumption.
%

%------------------------------------------------------------------------
\subsection{Types of Answer Subsumption}
\index{tabling!answer subsumption}

\subsubsection{Partial Order Answer Subsumption.}
% 
We illustrate the use of partial order answer subsumption through a
shortest-path predicate (Figure~\ref{fig:sp-preds}) that counts the
number of edges between two vertices.
%
\begin{figure}[htb]
{\small
\begin{verbatim}
sp(X,Y,1):- edge(X,Y).
sp(X,Z,N):- sp(X,Y,N1),edge(Y,Z),N is N1 + 1.
\end{verbatim}
} 
\caption{A Shortest Path Predicate}\label{fig:sp-preds}
\end{figure}

As mentioned above, partial-order answer subsumption retains in a
table $T$ only those answers that are maximal according to a given
partial order $>_O$.  In the case of the shortest-path predicate of
Figure~\ref{fig:sp-preds}, $sp(A_1,A_2,A_3) >_O sp(B_1,B_2,B_3)$ if,
$A_1 = B_1$, $A_2 = B_2$, and $A_3 < B_3$.  Note that that minimal
distances are maximal in $<_O$, and that $<_O$ is undefined if $A_3$
or $B_3$ is non-numeric.  In XSB, partial order answer subsumption
is specified for {\tt sp/3} using the declaration
%
{\small
\begin{verbatim}
  :- table sp(_,_,po((<)/2)).
\end{verbatim}
}
%
\noindent
In a given state of computation, only those answers that are maximal
according to $>_O$ are available for resolution.  Thus, for a finite
graph with cycles, {\tt sp/3} will terminate using answer subsumption,
but not with answer variance.  Other partial orders beyond distance
metrics may be useful.  For instance, $>_O$ may specify a preference
ordering between derived atoms so that answer subsumption provides an
alternative to default-based methods for computing preferences.

The treatment of variables in calls to partial order answer
subsumptive tabled predicates deserves mention.  Variables in
arguments not in the subsumption position are treated as ``group-by''
variables: i.e., for each value such a variable can take, a different
aggregate is computed.  So for example a call to \verb|sp(a,X,SD)|
will succeed for each node reachable from \verb|a|, binding \verb|X|
to that node and \verb|SD| to the shortest distance from \verb|a| to
that node.  One can place a \verb|^| in a non-subsumption position of
table declaration, e.g.,
%
{\small
\begin{verbatim}
  :- table sp(_,^,po((<)/2)).
\end{verbatim}
}
%
\noindent
to indicate that values of that position should be aggegated over.
For example, with this table declaration, the call \verb|sp(a,X,SD)|
will find the distance to the closest node reachable from \verb|a|,
(which, if \verb|a| has any successors, will be $1$, since a successor
to \verb|a| will be a nearest reachable successor at distance $1$ from
\verb|a|.)

Non-variables in the subsumption position in a call will be treated as
selecting what answers are included in the aggregation.

\subsubsection{Lattice Answer Subsumption.}
\index{tabling!answer subsumption}
An upper semi-lattice is a partial order for which any two elements
have a unique least upper bound.  Because the ordering for the third
argument of {\tt sp/3} is total, it also forms an upper semi-lattice,
and so can be computed using lattice answer subsumption.
~\footnote{The terminology lattice answer subsumption is employed even
  though only the join of the lattice is used.}.  In XSB lattice
answer subsumption for {\tt sp/3} is declared as
%
{\small
\begin{verbatim}
  :- table sp(_,_,lattice(min/3)).
\end{verbatim}
}
%
\noindent
with {\tt min/3} defined as {\tt min(X,Y,Z):- Z is min(X,Y).} 
Operationally, this means that whenever an answer
$sp(A_1,A_2,A_3)$ is derived, if there is another answer
$sp(B_1,B_2,B_3)$ where $A_1 = B_1$ and $A_2 = B_2$ the join $J_3$ of
$A_3$ and $B_3$ is taken, and only $sp(A_1,A_2,J_3)$ is available for
resolution.  As with a partial order, the join operation
ensures termination for shortest path over a finite graph with cycles.
\index{termination!answer subsumption}

As the following proposition shows, lattice answer subsumption can be
modeled either starting with a lattice, or starting with a function
with appropriate properties.
\begin{proposition}
Let {\em op} be an associative, commutative, and idempotent binary
function.  Then there is a partial order $P$, such that $P$ is an
upper semi-lattice with join {\em op}.
\end{proposition}
% 
Conversely, if a function does not have the above properties, it is
not suitable for lattice answer subsumption.  Accordingly the
aggregate functions count and sum cannot be computed using lattice
answer subsumption~\footnote{Since count and sum are not idempotent
  their semantics is based on multi-sets, rather than sets.
  Incorporating these as tabling features requires modifying their
  semantics to be set-based, in a manner similar to aggregation ASP
  systems.}.
%
Lattice answer subsumption has a variety of applications.
\cite{SwiW10a} shows how it is used for social-network analysis and
Section~\ref{sec:mv} shows its use for an application of multi-valued
logics, \cite{Swif99a} describes how a similar formalism can implement
a quantitative logic, and \cite{RigS11a,RigS13} describes how XSB's
{\tt PITA} package is based on answer subsumption (see Volume 2 of
this manual).

\subsubsection{Partial Order Answer Subsumption with Abstraction.}
\index{tabling!answer subsumption}
Computation over an abstract domain may require certain maximal
answers to be abstracted.  In many cases, abstraction can be modeled
by a join operation, but in others the abstraction represents an
implicit induction step in the following sense. Given a set $\cA$ of
answers, it may be detected that the program computed does not have a
finite model.  An abstraction operation then is applied so that $\cA$
and its extensions can be symbolically represented by a single answer
$A$.  Using answer subsumption, this abstraction can be taken only if
needed during program execution.  Abstractly, partial order answer
subsumption with abstraction uses the declaration {\small
\begin{verbatim}
:- table p(_,_,po(rel/2,abs/3)).
\end{verbatim}
} 
%
\noindent
where {\tt rel/2} is a partial order, and {\tt abs/3} is the
abstraction operation.  Section~\ref{sec:abs-int} provides a detailed
example of how such an approach is used to analyze a process logic.

\subsection{Examples of Answer Subsumption} \label{sec:answer-subsumption-examples}
\index{tabling!answer subsumption}

\subsubsection{Answer Subsumption and Abstract Interpretation} \label{sec:abs-int}
%
Net-style formalisms, such as Petri Nets, Workflow Nets, etc. have
been used extensively for process modeling.  Reachability is a central
problem in analyzing properties of such nets, to which properties such
as liveness, deadlock-freedom, and the existence of home states can be
reduced.  However, many interesting net formalisms cannot guarantee a
finite number of configurations in a given net, so abstraction methods
must be applied for their analysis.
\index{answer abstraction}

%\dsw{Should say
%that a transition removes one token from the places that are the
%sources of its input edges and adds one token to each place at the
%target of each of its output edges.  Also I don't see a
%``configuration'' in figure 7; that should be some number of tokens
%at each place, no?}
For instance, the lack of finiteness is a problem in analyzing
Place/Transition (PT) Nets.  PT nets have no guard conditions or
after-effects, and do not distinguish between token types.  However,
PT nets do allow a place to hold more than one token, leading to a
potentially infinite number of configurations.  This can be seen in
the simple network of Figure~\ref{fig:ptnet} (from~\cite{DesR98}) in
which transitions are denoted by squares and places by circles.  Each
transition removes one token from the places that are the sources
of its input edges and adds one token to each place at the target of
each of its output edges.  Starting from the configuration in
Figure~\ref{fig:ptnet}, repeated application of transition {\tt t1}
leads to place {\tt s2} containing an unbounded number of tokens;
repeated application of the sequence {\tt t1,t2,t3,t4} leads to place
{\tt s4} containing an unbounded number of tokens.
%
\begin{figure}
\centering
\includegraphics[width=0.5\textwidth]{omegaNet}
%%\epsfig{file=omegaNet,width=.5\textwidth}
\caption{A PT-net and configuration with an infinite number of reachable configurations} 
\label{fig:ptnet}
\end{figure}
%

Despite such examples, reachability in PT nets is decidable and can be
determined using an abstraction method called $\omega$-sequences, (see
e.g. \cite{DesR98}).  The main idea in determining $\omega$ sequences
is to define a partial order $\geq_{\omega}$ on configurations as
follows.  If configurations $C_1$ and $C_2$ are both reachable, $C_1$
and $C_2$ have tokens in the same set $PL$ of places, $C_1$ has at
least as many tokens in each place as $C_2$, and there exists a
non-empty $PL_{sub} \subseteq PL$, such that for each $pl \in
Pl_{sub}$ $C_1$ has strictly more tokens than $C_2$, then $C_1
>_{\omega} C_2$.  When evaluating reachability, if $C_2$ is reached
first, and then $C_1$ was subsequently reached, $C_1$ is abstracted by
marking each place in $PL_{sub}$ with the special token $\omega$ which
is taken to be greater than any integer.  If $C_1$ was reached first
and then $C_2$, $C_2$ is treated as having already been seen.

Tabling combined with partial order answer subsumption requires
slightly over 100 lines of code to model reachability in PT nets using
$\omega$-sequences.  Due to space restrictions, the program cannot be
fully described here, but the top-level reachability predicate is
shown in Figure~\ref{fig:ptnetcode}.  Despite its succinctness, it can
evaluate reachability in networks with millions of states in a few
minutes.  This use of tabling to determine reachability in PT nets can
be seen as a special case of tabling for abstract interpretation
(cf. \cite{KaKa93} and other works).  However the framework for answer
subsumption described here allows tabling to be used to efficiently
perform abstract interpretation within a general Prolog system
%
\begin{figure}
\begin{verbatim}
:- table reachable(_,po(omega_gte/2,omega_abs/3)).
reachable(InConf,NewConf):-
        reachable(InConf,NewConf),
        hasTransition(Conf,NewConf).
reachable(InConf,NewConf):- hasTransition(InConf,NewConf).
\end{verbatim}
\caption{Top-level predicate for PT net reachability}
\label{fig:ptnetcode}
\end{figure}

\subsubsection{Scalability for multi-valued and quantitative logics} \label{sec:mv}
\index{tabling!answer subsumption}
%
The technique of program justification (cf. e.g. \cite{PGDRR04}) has
been used for debugging tabled programs that cannot be debugged by
traditional means.  Here, we consider justification in the context of
the Silk system, currently under development at Vulcan, Inc.  Silk is
a commercial knowledge representation and rule system built on top of
Flora-2, which is implemented using XSB.  One of the salient features
of Silk is its default reasoning, which is based on a parameterized
argumentation theory evaluated under the well-founded
semantics~\cite{WGKFL09}.  One issue in using Silk is that knowledge
engineers must have a way of understanding the reasoning of the
system, a task complicated by the use of the well-founded semantics
and the intricacies of the argumentation theory.  We describe an
experimental approach to justification of Silk-style argumentation
theories using multi-valued logics.

As noted in~\cite{WGKFL09}, argumentation theories in Silk are usually
extensions of the default theories of Courteous Logic Programs (CLP)
and are based on two user-defined predicates: {\tt opposes/2} and {\tt
  overrides/2}.  Two atoms {\em oppose} each other if no model of a
program can contain both atoms: an atom and its explicit negation
oppose each other, but opposition can capture many other types of
contradictions.  Given two opposing atoms, one atom may {\em override}
the other, and so be given preference.  For atoms $A_1$ and $A_2$, if
$A_1$ and $A_2$ are both derivable and oppose each other but neither
overrides the other, $A_1$ and $A_2$ mutually {\em rebut} each other.
If in addition $A_1$, say, overrides $A_2$, $A_1$ {\em refutes}
$A_2$~\footnote{In~\cite{WGKFL09} argumentation theories are built on
  named rules, here we base them on derived atoms.}.  Within Silk and
Flora-2, the compilation of an argumentation theory ensures that
rebutted atoms have an undefined truth value, as do atoms that refute
themselves (i.e. if the {\tt overrides/2} predicate is cyclic).
However, for justification, it is meaningful to distinguish those
facts that are undefined due to a negative loop in the argumentation
theory from those that are undefined due to a negative loop in the
program itself.  In addition, it is meaningful to distinguish an atom
that is true because it overrides some other atom, from an atom whose
derivation does not depend on the argumentation theory.  Similar
distinctions can be made for default false literals leading to the
truth lattice shown in Figure~\ref{fig:courteous}.
\begin{figure}
\comment{
\small{
\begin{verbatim}
:- table defeated/1.
defeated(A):-  defeated_by(A,_B).       defeated(A):-  defeats(A,_B).

defeated_by(A,B):- refutes(B,A),B.      defeats(A,B):- refutes(A,B),B.	        
defeated_by(A,B):- rebuts(B,A),B.       defeats(A,B):- rebuts(A,B),B.		

refutes(A,B):- conflicts(A,B), overrides(A,B).
rebuts(A,B):- conflicts(A,B).

conflicts(A,B):- opposes(A,B),A.        conflicts(A,B):- opposes(B,A),A.
\end{verbatim}
}}
\centering
\includegraphics[width=0.45\textwidth]{courteous2}
%%\epsfig{file=courteous2,width=.45\textwidth}
\caption{A Truth Lattice for a Simplified Version of Courteous Argumentation Theory} 
\label{fig:courteous}
\end{figure}
%

\subsection{Term-Sets}

XSB provides support for a programming technique for representing sets
of terms, called term-sets.  (While it is not closely related to
answer subsumption, it is partially implemented through tabling and a
table declaration, and so this facility is documented here.)

We begin in an example.  We can represent a set of Prolog terms by
using a particular term of the form \verb|{Var:Goal}| where Goal has
(only) \verb|Var| free in it.  Then we will use this \emph{set-term} to
represent the set of terms obtained by evaluating \verb|Goal| and
taking the values of \verb|Var| that are obtained.  I.e., they would
be the terms in the list \verb|L| returned by the Prolog call to
\verb|setof(Var,Goal,L)|. For example, the set-term:
\begin{verbatim}
{X : member(X,[a,b,c])}
\end{verbatim}
represents the set of terms \verb|{a,b,c}|.

Now a \emph{term-set} is a Prolog term that may contain set-terms as
subterms.  For example,
\begin{verbatim}
m({X:member(X,[a,b,c])},g(d,{Y:member(Y,[e,f,g])}),h)
\end{verbatim}
is a term-set, and it represents the set of terms obtained from it by
replacing (recursively) any embedded set-term by a term in that
set-term.  So the above term-set represents the 9 terms:
\begin{verbatim}
m(a,g(d,e),h)        m(a,g(d,f),h)        m(a,g(d,g),h)
m(b,g(d,e),h)        m(b,g(d,f),h)        m(b,g(d,g),h)
m(c,g(d,e),h)        m(c,g(d,f),h)        m(c,g(d,g),h)
\end{verbatim}
This example shows an advantage of this representation.  Say a
term-set has $k$ sub-set-terms each of which is of the member form in
this example where each member has a list of atoms of length $n$.  To
represent this set of terms explicitly takes $O(n^k)$ space, whereas
to represent them with the term-set takes only $O(n \times k)$ space.  So a
term-set representation can take exponentially less space than an
explicit representation.

It is relatively easy to write a predicate, {\tt member\_termset/2},
which takes a variable and a term-set
and non\-deterministically generates all concrete terms represented by
the term-set, called \emph{extensionalizing} the term-set.  Some care
must be taken since a call to goal to extensionalize a set-term may
itself return a term-set.  Also term-sets can be self-recursive and
thus represent infinitely many Prolog terms.  For example, consider
the term-set:
\begin{verbatim}
{X : p(X)} where
  p(a).
  p(f({X:p(X)})).
\end{verbatim}
This term-set represents the terms for which {\tt p/1} is true.  Now
{\tt p(a)} is true, so {\tt a} is in the term-set.  Since {\tt a} is
in \verb|{X:p(X)}|, then {\tt p(f(a))} is true because of the second
fact for {\tt p/1}, and so {\tt f(a)} is in the term-set.  And so on.
So this term-set contains the infinitely many terms:
\begin{verbatim}
a, f(a), f(f(a)), f(f(f(a))), ...
\end{verbatim}

A particularly interesting use of term-sets is in conjunction with
tabling.  Consider the term-set \verb|{X:p(1,2,X)}| where {\tt p/3} is
tabled.  If \verb|p(1,2,_}| has been called and so its table is
filled, then extensionalizing this term-set requires just a table
lookup; in some sense we can think of such a term-set as standing for
a pointer into a table to a set of terms.  This can be elegantly used
to solve an important problem in handling parse trees in context-free
parsing.

Consider the following DCG for the language {\tt a}*:
\begin{verbatim}
:- table a/3.
a(a(P1,P2)) --> a(P1),a(P2).
a(a) --> [a].
\end{verbatim}
which recognizes a string of {\tt a's} and constructs its parse trees.

To generate all answers, this DCG will take time exponential in the
length of the input string; not surprising since there are
exponentially many parses.  But say we give it an input string of $n$
{\tt a}'s followed by one {\tt b}.  In this case it will take
exponential time to fail, since it will construct all the
exponentially many partial parse trees for the initial $k$ {\tt a}'s.
We would like the parser in this case to fail in polynomial time.  We
can do this by representing the parse trees as a term-set during the
recognition of the string.  Then after the string is recognized, we
extensionalize the set-term that represents the parse trees.  In this
way we can get the behavior we want.  The set-term that represents the
parse trees for any grammar will be constructed in polynomial time;
the extensionalization of that term-set will take exponential time
only if there are exponentially many parses.

We can cause XSB to automatically use the term-set representation for
the grammar by adding to the above program the declaration:
\begin{verbatim}
:- table a(termset,_,_).
\end{verbatim}
which tells XSB to use the term-set representation of the first
argument of nonterminal {\tt a/3}.

With this declaration, the XSB compiler transforms the above program
into the following:
\begin{verbatim}
:- table a/3.

a(a(P1,P2),S0,S) :- '_$a'(P1,S0,S1),'_$a'(P2,S1,S).
a(a,S0,S1) --> 'C'(S0,a,S1).

:- table '_$a'/3 as subsumptive.
'_$a'({X:'_$a'(X,S0,S)},S0,S) :- a(_,S0,S).
\end{verbatim}
A new predicate {\tt '\_\$a'/3} has been introduced, and all calls to the
original predicate {\tt a/3} are replaced by calls to the new one.  It
is defined to call the original {\tt a/3} but to return the term-set
instead of the concrete parse tree in the argument declared to be a
term-set.

We can see that a call to {\tt a/3} in this new program will have
exactly as many answers as the corresponding call to {\tt a/2} in the
original recognizing DCG, since given values for {\tt S0} and {\tt S},
a call to {\tt '\_\$a'/2} returns only one value in its first
argument.  So a call to {\tt a/3} with have the polynomial complexity
of the recognizer.  So now when this representation is used, one gets
the concrete parse tree for a string by writing, for example:
\begin{verbatim}
| ?- a(Pts,[a,a,a,a,a,a,a],[]), member_termset(Parse,Pts).
\end{verbatim}
Here the term-set representing the parses for the sequence of {\tt
a}'s will be returned in the variable {\tt Pts}, and then {\tt
member\_termset} is used to extensionalize it
to the produce the actual explicit parse
tree.  With this way of handling parse trees in arbitrary context-free
grammars, the complexity of parsing to create the term-set is always
polynomial, and then extensionalizing the term-set may be exponential
if all parses are desired and there are exponentially many of them.
(In fact, if the grammar contains a rule such as \verb|A --> A|, there
may be infinitely many parses.)
Of course, if the parsing call to {\tt a/3} fails, then there is no
extensionalization to do, and the process is polynomial.

Note that the transformation uses subsumptive tabling for the newly
introduced auxiliary predicate.  This is important for this example,
since the parsing calls to {\tt '\_\$a'/3} will normally have {\tt S0}
bound and {\tt S} free, yet when extensionalizing the constructed
term-set to obtain the parse trees, the calls will have both {\tt S0}
and {\tt S} bound.  We do not want to recompute the parse during
extensionalizion, which would happen were we to use variant
tabling, and so we use subsumptive tabling.

Problems in graph traversal provide another example of the effective
use of term-sets.  For graph reachability, we have the very familiar:
\begin{verbatim}
:- table reach/2.
reach(X,Y) :- edge(X,Y).
reach(X,Y) :- reach(X,Z), edge(Z,Y).
\end{verbatim}
which is linear in the number of edges in the graph.  But say that we
now want to construct the path from X to Y when Y \emph{is} reachable
from X.  One simple way to do it (collecting the intermediate nodes in
the path in reverse order) is:
\begin{verbatim}
:- table path/3.
path(X,Y,[]) :- edge(X,Y).
path(X,Y,[Z|Path]) :- path(X,Z,Path), edge(Z,Y).
\end{verbatim}
For an acyclic edge graph, this works fine, but for a graph with
cycles, this will go into an infinite loop.  Indeed, it must, since in
a cyclic graph there \emph{are} infinitely many different paths between
some nodes.  However, we can use term-set to handle this situation
more flexibly.  We modify the above program by adding:
\begin{verbatim}
:- table path(_,_,termset).
\end{verbatim}
With this declaration, every call to {\tt path/3} (for a finite edge
graph) will terminate in time linear in the number of edges.  And all
the paths will be presented in the term-set returned in the third
argument.  Here we have an advantage similar to the one we had in the
grammar example above: if there is no path from our source to our
target node, we will find that out in linear time.  Without the
term-set declaration, this might take exponential time, while the
program builds all the paths to all the nodes that \emph{are} reachable
from our source node.  Also, if we want only \emph{one} possible path
from our source to our target, we can easily retrieve only one member
of the term-set during extensionalization, and the whole process is
still linear.

Now consider what happens with when the graph has cycles.  In this
case, the term-set may be recursive and represent the infinitely many
paths between nodes.  For example, the term-set representing all paths
from {\tt a} to {\tt a} in the graph with a single edge from {\tt a} to
{\tt a} will have the same structure as the example of an infinite
term-set given at the beginning of this subsection.  Once the path
term-set is constructed (in time linear in the number of edges for a
single source), producing paths reduces to processing the term-set
structure.  For example to generate all paths between nodes which do
not contain repeated intermediate nodes, one could write an
extensionalization predicate that passes a list of term-sets in the
process of being expanded, and refuse to re-expand one currently being
expanded.  This is the technique often used in Prolog without tabling
to compute reachability in cyclic graphs.

All of these examples can be seen as special cases of constructing
proof trees or justifications of goals.  Indeed, term-sets could be
effectively used in the construction of a justification or explanation
system.

\index{termination!subgoal abstraction}
\index{bounded rationality}
\index{termination!radial restraint}
\index{termination!answer count restraint}
\index{abstraction of terms!subgoal}
\index{abstraction of terms!answer}
\section{Tabling for Termination} \label{sec:tabling-termination}
%
As noted throughout this manual, tabling adds important termination
properties to programs and queries.  In this section we state more
precisely what these termination properties are, and how the
properties can be strengthened through declarations and settings for
{\em subgoal abstraction} and for sound bounded rationality through a
type of answer abstraction called {\em radial restraint} as well as by
limiting the number of answers to a subgoal through {\em \maxans{}
  restraint}.

Before proceeding, it is important to set the context for where issues
of termination may arise.  Consider first a pure normal program in
which every predicate is tabled.  This means a program where rules may
only call other rules, possibly through negation ({\tt tnot/1}, {\tt
  not\_exists/1} or {\tt u\_not/1} in XSB); but where there are no
calls to built-in all-solutions predicates, or other built-ins.  If
such a fully-tabled pure normal program does {\em not} have function
symbols, XSB will always terminate for any query.  For instance, XSB
will terminate for fully tabled pure datalog programs -- even if the
head of a rule is ``unsafe'' in that it contains variables that do not
occur in the body of that rule~\footnote{Evaluations that call
  non-ground negative literals will terminate through floundering,
  although this can be avoided in most cases by using {\tt
    not\_exists/1}.}.  Such programs are sometimes called \emph{datalog}
programs.

While datalog programs are useful for certain kinds of knowledge
representation, they are not powerful enough for general programming
as they do not allow recursive structures such as lists.  Thus, for
the rest of this section we consider pure programs that may contain
function symbols.  Consider a pure definite program in which every
predicate is tabled.  Such a program would create a table for each
tabled subgoal (up to variance) exactly once if call variance were
used, and at most once if call subsumption were used.  In addition,
tabling guarantees that each answer will be returned to each call to a
tabled subgoal at most once.  This means that there are two sources of
non-termination.  Either there can be an infinite number of subgoals,
or there can be an infinite number of answers.\footnote{Here, forest
  of trees model of tabling (cf. Section~\ref{sec:forest-trace}) is
  being implicitly used.}

\paragraph{An Infinite Number of Subgoals}
%
If a definite program produces an infinite number of subgoals {\em
  but} has a finite number of answers, the program can be made to
terminate by abstracting the subgoal.  For instance, consider the
program fragment:
%
\begin{verbatim}
:- table p/1.
p(X) :- p(f(X)).
\end{verbatim}
%
The goal {\tt ?- p(1)} can create an infinite number of tabled
subgoals: {\tt p(f(1))}, {\tt p(f(f(1)))}, {\tt p(f(f(f(1))))} and so
on.  Note that since all of the subgoals are ground, none subsume one
another, so that call subsumption will not help here. (Although call
subsumption is extremely useful in other circumstances, and would terminate
if the goal were {\tt ?- p(X)}).

\paragraph*{Infinite Answers}
%
Of course, subgoal abstraction can't handle cases where there are an
infinite number of answers, as in the program fragment:
%
\begin{verbatim}
p(f(X)) :- p(X).
p(1).
\end{verbatim}
%
when given the query {\tt ?- p(X)}.  

We consider each case in turn.

\subsection{Term Size Abstraction in XSB} \label{sec:size-metric}
\index{abstraction of terms!size metric}
%
Both subgoal and answer abstraction in XSB are based on limiting the
size of any argument of a term $T$ that forms a subgoal or answer.
The specific definition of size used is slightly complicated, but
offers advantages as discussed below.  Each argument $T_a$ of $T$ is
traversed as follows.  The size of $T_i$ is initialized to 0, then
$T_a$ is traversed from left to right.  Each time a non-constant
functor or list symbol is encountered, the size of $T_i$ is
incremented by 1 -- regardless of the type of functor symbol that is
encountered.  If the size of $T_a$ exceeds the associated size limit
for $T$ (as declared in the next section), all further non-constant
functor symbols encountered in $T_i$ will be abstracted (rewritten as
free variables).  Once $T_a$ has been fully traversed, further
arguments of $T$ will be traversed in the exact same manner.

%, with one
%important exception.  The functor symbols will be abstracted {\em
%  only} if they also occur at depth greater than 0.

\begin{example} \label{ex:term-size-abs}
Applying the above definition of size abstraction with limit 2 to the
term 

{\tt p(d(e(1),a,f(c$_1$)),b,g(c$_2$),[c$_3$,[c$_4$,c$_5$]]))}

\noindent
  produces the term 

{\tt p(d(e(X$_1$),a,X$_2$),b,g($c_2$),[$c_4$|X$_3$])}.  

\noindent
In the traversal, the size limit is reached once the {\tt e/1} functor
is encountered.  To the right of {\tt e/1}, all non-constant functor
symbols are abstracted when they occur at depth greater than 0.  This
causes {\tt f/1} to be abstracted, as it occurs at depth 1; however
{\tt g/1} in the third occurs at depth 0, and so is retained.
Similarly in the fourth argument, the outer list symbol and head is
preserved, while the tail of the list is abstracted.
\end{example}

Example \ref{ex:term-size-abs} indicates that the size abstraction
used in XSB excludes symbols of depth 0, and so is something of a
hybrid approach, although we continue to call it size abstraction.

Other metrics could be used, such as term depth, which would offer
conceptual clarity.  However size-based abstraction allows
finer-grained optimization than depth-based abstraction and offers the
following general advantages.
\begin{itemize}
\item From the point of view of implementation, the abstraction can be
  performed with manner that has minimal if any impact on the speed of
  XSB's tabling engine.
\item By not abstracting functor symbols at depth 0 and by abstracting
  each argument individually, both multi-argument indexing and star
  indexing of subgoals will be often be preserved.
\end{itemize}

\subsection{Subgoal Abstraction} \label{sec:subg-abs}
\index{abstraction of terms!subgoal}
%
In a nutshell, subgoal abstraction allows a goal like {\tt
  p(f(f(f(1))))} to be rewritten as 

{\tt p(f(f(X))),X = f(1)}.  

\noindent
If all subgoals that have a term size -- or term depth -- over a given
finite threshold are abstracted, any query can produce only a finite
number of subgoals (since there are a finite number of predicate,
function and constant symbols in any program). If a program has a
finite well-founded model, it can be shown that any query to a program
will terminate if that program uses subgoal abstraction~\cite{RigS14}.
%
For normal programs, the situation is not much different at a
conceptual level.  A goal such as {\tt tnot(p(f(f(f(1)))))} would
execute as {\tt p(f(f(X)))} and then ensure that none of the answers
to this goal have a binding for {\tt X} that allows it to unify with
{\tt f(1)}.  Using this intuition, it can be shown that if a program
has a well-founded model with a finite number of true or undefined
answers it will terminate using tabling with subgoal
abstraction~\cite{RigS13,RigS14}.

Despite its theoretical power, subgoal abstraction can also cause
problems if used indiscriminately.  For instance, if the second
argument of the subgoal
%
\begin{verbatim}
?- member(e,[a,b,c,d,e])
\end{verbatim}
%
is abstracted forming the goal
%
\begin{verbatim}
?- member(e,[a,b,c|X])
\end{verbatim}
%
leading to an infinite number of answers.  a goal that terminates
without abstraction will not terminate after abstraction.  Note that
any program containing {\tt member/2} and at least one constant does
not have a finite model (although any given ground query will have a
finite number of answers).  While an experienced programmer would not
usually table {\tt member/2}, s/he well may want to table a grammar or
other program that performs recursion through a finite structure.

\index{tripwires!max\_table\_answer\_size}
\subsubsection{Declaring Subgoal Abstraction}
%
% The implementation of subgoal abstraction in XSB is still in progress.
% and may be changed in future versions as we gain experience in how
% subgoal abstraction is best used in practice.  

XSB can perform subgoal abstraction based on the size limit described
above.  It will do so for goals called positively, but not for goals
called negatively as this would give rise to unsound negation.  Thus a
goal $G$ inside a construct such as {\tt tnot/1} or {\tt
  not\_exists/1} will throw an exception (or suspend into break mode)
if it surpasses the specified term size. In addition, subgoal
abstraction is only implemented for call variance, {\em and applies
  equally to all functors, whether they are lists or non-lists}.
Despite these restrictions, a tabled evaluation can be still
guaranteed to terminate for queries to safe programs
(cf.~\cite{RigS13}).

\index{Prolog flags!{\tt max\_table\_subgoal\_action}} 
\index{Prolog  flags!{\tt max\_table\_subgoal\_size}} 

Subgoal abstraction can be declared by setting a value for the maximum
size of a subgoal and for the action to take when a subgoal is
encountered that reaches that size.
%
\bi
\item {\bf size} The maximum size can be set to $n$ for a set of
  predicates $\langle PredSpec \rangle$ by including the specifier
  {\tt subgoal\_abstract(n)} as part of the tabling declaration

{\tt :- table $\langle PredSpec\rangle$  as ...,subgoal\_abstract(n),...}

  Specifying {\tt subgoal\_abstract(0)} turns abstraction off for
  predicates in $\langle PredSpec \rangle$.  The size can also be set
  globally by setting the flag {\tt max\_table\_subgoal\_size} to the
  desired maximal size.  If the subgoal size has been set of a given
  predicate via a tabling declaration the declared size will override
  the global size.

\item {\bf action} When a subgoal is encountered of maximum size,
  abstraction is enabled if the Prolog flag {\tt
    max\_table\_subgoal\_action} to {\tt abstract}.  Other possible
  values for the action are {\tt error} and {\tt suspend}
  (cf. pg. \pageref{prolog-flags} ff.).  \ei

\noindent
Unless otherwise specified, XSB starts up with {\tt
  max\_table\_subgoal\_action} set to {\tt error} and {\tt
  max\_table\_subgoal\_size} set to 0, indicating it is turned off.
Under this default behavior, XSB will throw an error if a subgoal has
size greater than {\tt max\_table\_subgoal\_size}.  As an alternative
to setting flags, subgoal abstraction can be set by calling XSB with
the command-line arguments {\tt --max\_subgoal\_action a} and {\tt
  --max\_subgoal\_size n} with {\tt a} the desired action and {\tt n}
the desired size limit.

\subsection{XSB's Approach to Bounded Rationality} \label{sec:restraint}
\index{abstraction of terms!answer}
\index{bounded rationality}
%
Bounded rationality is a subfield of Artificial Intelligence that
studies how the reasoning performed by a computation can be
automatically bounded so that an agent or other program can be
guaranteed to arrive at a decision ``quickly''.  By bounding
reasoning, an agent may be used in a setting that requires reactivity
or where a simulation of human reasoning is needed.

%Thus, the approximation that XSB computes is {\em
%  informationally sound} in the sense that no incorrect answer will be
%derived, although the truth value of some atoms won't be known that
%might have been if the size bound had been set higher.  

XSB's approach to bounded rationality computes a finite approximation
to the well-founded model that is {\em informationally sound} in the
sense that no incorrect answer will be derived, although the truth
value of some atoms won't be known. In other words, if bounded
rationality is employed, it can be guaranteed that only a finite
number of answers will be derived~\cite{GroS13}.  Furthermore, any
true atom that XSB derives is true in the well founded model of a
program; and any goal that fails is false in the well-founded model.
However, by bounding rationality XSB's search is restrained so that it
will not fully explore certain subderivations and so may consider as
undefined some atoms that are true or false in the well-founded model.
We sometimes call this approach to bounded rationality {\em
  restraint}.  Currently XSB supports both {\em radial restraint} and
{\em \maxans{} restraint}

\index{restraint!radial}
\subsubsection{Radial Restraint Through Answer Abstraction}
Radial restraint resembles subgoal abstraction (Section
\ref{sec:subg-abs}) in certain ways, as can be seen in the following
example. If the query {\tt p(X)} to the program
%
\begin{verbatim}
p(f(X)) :- p(X).  
p(0).
\end{verbatim}
%
were evaluated using radial restraint with a size limit of 3, the
answers, {\tt p(0)}, {\tt p(f(0))}, {\tt p(f(f(0)))} and {\tt
  p(f(f(f(X))))} would be generated; {\bf {\em however}}, {\tt
  p(f(f(f(X))))} would have the truth value of {\em undefined}.  Note
that by abstracting in this way, both of the goals {\tt
  p(f(f(f(0))))}, and {\tt p(f(f(f(1))))} will unify with {\tt
  p(f(f(f(X))))} and so will succeed with a truth value of {\em
  undefined}.  Similarly {\tt tnot(p(f(f(f(0)))))}, and {\tt
  tnot(p(f(f(f(1)))))} will both succeed with a value of {\em
  undefined} (perhaps better called {\em unknown} in this context).
%
It can be seen that since all predicates and function symbols have a
maximum arity (256 in XSB) bounding the size of an answer ensures that
only a finite number of answers are returned
\footnote{If a program has a infinite number of true answers and a
  finite number of false answers, one possible approach might be to
  ``dualize'' the program so that only false answers are computed.
  Note that since most programs with function symbols have an infinite
  number of both true and false answers, this approach won't work in
  general.}.

Semantically when radial restraint is used, XSB computes an
approximation to the three-valued well-founded model of a program,
called a {\em restrained model}.  To see this, suppose the proof of a
query $Q$ does not depend on negation.  If $Q$ has a derivation that
does not require any answers whose size is greater than $n$, it is
proven as usual.  Similarly, if $Q$ is false in the well-founded model
of a program, and none of the subgoals explored in the derivation of
$Q$ derive answers whose size is greater than $n$, XSB will derive
that $Q$ is false.  The higher the size bound that is set, the better
the approximation.  Due to undecidability, there is no way to know in
general what size to set for answer abstraction, or whether any bound
needs to be set at all.

If a restrained model is derived, answers that are directly undefined
through radial restraint can be distinguished from answers that are
undefined in the well-founded model of a program, or for other reasons
such as unsafe negation.  If an answer $A$ was abstracted due to a
size check, the query {\tt get\_residual(A,Delay)} would bind {\tt
  Delay} to a list containing the atom {\tt radial\_restraint}, where
{\tt radial\_restraint/0} is simply a predicate defined as

{\tt radial\_restraint:- tnot(radial\_restraint)}

%\noindent
%which in a delay list indicates that an answer was made undefined
%through bounded-rationality based answer abstraction.

\index{tripwires!max\_table\_answer\_size}
\paragraph*{Using Radial Restraint}
%
Radial restraint is currently implemented only for tabling with call
variance.  However it works with most other tabling features, such as
call abstraction, and incremental tabling.
%
Similarly to the use of subgoal abstraction, answer abstraction is the
implementational basis of radial restraint.  As shown in the following
example, {\em it is important to note that the size limit applies to
  the answer substitution, not to the size of the answer itself.}

\begin{example}
Suppose an answer size limit is set to 1, and consider the goal {\tt
  p(X)}.  The answer {\tt p(s(s(0)))} has size 2 and so would be
abstracted to {\tt p(s(X$_1$))} as expected, as the corresponding
abswer substitution is $X = s(s(0))$.  However for the goal {\tt
  p(s(X))} the answer substitution for the answer {\tt p(s(s(0)))} is
$X = s(0)$ which has a size of only 1 and so this answer would not be
abstracted in the context of this subgoal.  Despite this difference in
how the size metric is computed, the termination and approximation
properties of radial restraint still hold.
\end{example}

Radial restraint can be declared by setting a value for the maximum
size of an answer and for the action to take when an answer is
encountered that reaches that size.
%
\bi
\item {\bf size} The maximum size can be set to {\tt n} for a set of
  predicates by including the specifier {\tt answer\_abstract(n)} as
  part of their tabling declaration

{\tt :- table $<PredSpec>$ as ...,answer\_abstract(n),...}

  Specifying {\tt answer\_abstract(0)} turns answer abstraction off
  for predicates in $\langle PredSpec \rangle$.  The size can also be
  set globally by setting the flag {\tt max\_table\_answer\_size} to
  the desired maximal size.  If the answer size of a given predicate
  has been set via a tabling declaration, the predicate-specific
  declared size will override the global size.

\item {\bf action} When an answer is encountered of maximum size,
  abstraction is enabled if the Prolog flag {\tt
    max\_table\_answer\_action} to {\tt abstract} (or, equivalently,
  to {\tt bounded\_rationality}).  Other possible values for the
  action are {\tt error}, {\tt suspend} and {\tt custom} (cf. Section
  \ref{sec:tripwire} for further information).  \ei


\index{Prolog flags!{\tt max\_table\_answer\_action}} 
\index{Prolog flags!{\tt max\_table\_answer\_size}}
%
Unless otherwise specified, XSB starts up with {\tt
  max\_table\_answer\_size\_action} set to {\tt error} and {\tt
  max\_table\_answer\_size} set to 0.  
%

\subsubsection{\MAXANS{} Restraint} \label{sec:answer-count-restraint}
\index{tripwires!max\_answers\_for\_subgoal}
\index{restraint!answer count}

As discussed above, finite termination -- and some types of bounded
rationality -- can always be ensured through a mixture of subgoal
abstraction and radial restraint.  Alternately, these features can
also be ensured through subgoal abstraction and \maxans{} restraint.

\begin{example} \label{ex:maxans}
Consider the program

\begin{verbatim}
:- table p/4.
p(M,N,X,Y):- between(1,M,X),between(1,N,Y).
\end{verbatim}

\noindent
and query {\tt p(3,3,Y,Z)}: it is easy to see that 9 answers will be
produced.  However, if \maxans{} restraint is used to restrict the
maximal number of answers to each subgoal to 5, the first 5 answers
computed above will be returned, along with a new answer:

{\tt p(3,3,Y,Z)}

\noindent
whose truth value is undefined, with the atom 
%
{\tt \maxUans\_restraint} in its delay list.
\end{example}

Using the arguments from the previous section, it is easy to see that
\maxans{} restraint ensures sound finite termination when used with
subgoal abstraction.  However Example~\ref{ex:maxans} also illustrates
on a small scale how \maxans{} restraint can be used to soundly
complete a subgoal $S$ once a minimal number of answers have been
derived, even if $S$ has a large, but finite number of answers.

\paragraph*{Using \MAXANS{} Restraint}
\Maxans{} restraint is currently implemented only for tabling with call
variance.  However it works with most other tabling features, such as
call abstraction, and incremental tabling.

Currently, \maxans{} restraint can only be set by global flags as
follows.
\bi
\item {\bf size} The size can be set globally via the flag {\tt
  max\_table\_answer\_size} to the desired maximal size.  Setting the
  flag to 0 turns off \maxans{} restraint.

\item {\bf action} When an answer is encountered of maximum size,
  abstraction is enabled if the Prolog flag {\tt
    max\_table\_answer\_action} to {\tt complete\_soundly}.  Other
  possible values for the action are {\tt error}, {\tt suspend} and {\tt custom}
  (cf. Section \ref{sec:tripwire} for further information).  \ei

\subsubsection{Justifying or Explaining Restraint}

An atom affected directly by radial or answer count restraint has in
its delay list either the atom {\tt radial\_restraint} or {\tt
  answer\_count\_restraint}.  The indirect dependency of an atom on a
form of restraint can be obtained either through the predicate {\tt
  explain\_u\_val/3}, or {\tt get\_residual\_sccs/[3,5]}.  Both of
these predicates traverse the residual dependency graph to provide
information about why a literal is undefined.

\index{residual dependency graph}
\predref{explain\_u\_val/3}
\predref{get\_residual\_sccs/3}
\predref{get\_residual\_sccs/5}

%--------------------------------------------------------------------
\input{incr_tabling}
%--------------------------------------------------------------------

\section{A Weaker Semantics for Tabling}
%
\index{completion semantics}
\index{completion semantics!weak}
Recall that the well-founded semantics (WFS) is weaker than, say,
the Stable model semantics.  For instance a program like
%
\begin{verbatim}
p:- not q.            q:- not p.
\end{verbatim}
%
has two stable models: $\{p\}$ and $\{q\}$.  On the other hand, WFS
has a single model, where both $p$ and $q$ are undefined.  This, of
course, is characteristic of the way WFS treats atoms whose only
non-failed derivations are based on a ``negative loop''.

However, an even weaker logic is possible where derivations based on
positive loops are also considered undefined.  In other words the
program
\begin{verbatim}
   r:- r.                r:- false.
\end{verbatim}
would assign the truth value {\em undefined} to $r$, although both WFS
and stable models would assign r as {\em false}.  But why use such a
weak logic?

Consider a woman who asks her husband when he'll clean the garage, and
the husband says:

{\em I'll get around to it when I get around to it.}

The wife would probably consider it ambiguous not only when her
husband might clean the garage, but whether he would do so at all.
The wife's reasoning (slightly simplified) could be rendered in logic
as:

\begin{verbatim}
   clean_the_garage:- clean the garage.
\end{verbatim}
\noindent
and we'd like to assign {\em undefined} or {\em unknown} to {\tt
  clean\_the\_garage}.\footnote{Actually, many wives would go ahead
  and assign {\em false} to this statement, but we are modeling an
  optimistic (or possibly delusional) wife.}

Although this example is somewhat fanciful, it turns out that this
interpretation accords with the results of cognitive science
experiments about human reasoning~\cite{SteV08}, and is known in the
logic programming community as the ``completion semantics'' (CS).  CS
differs from WFS only in assigning the truth value {\em undefined} to
derivations that depend on a positive loop, and that are otherwise not
satisfiable (cf. \cite{Lloy84}).

%Thus, in this
%new semantics positive loops are treated in an analogous way to
%negative loops.Formally, the new semantics can be expressed as a fixed
%point logic based on Clark's completion semantics~\cite{??}, when
%logical expressions are satisfied according to the Lukasiewicz
%3-valued semantics for propositional programs, which is weaker than
%some other approaches to 3-valued satisfiability, namely that of
%Kleene (see \cite{??}).  However, this level of formality is not
%necessary as long as one understands how positive and negative loops
%are evaluated.  We call this semantics the {\em completion semantics
%  (CS)}.

So as useful as WFS and stable models are for programming, they don't
reflect how human beings have been shown to reason in daily life.
However, there is another difference between WFS and the sort of
common-sense reasoning that humans perform.  WFS has a strong {\em
  closed-world} assumption.  Suppose a query {\tt ?- s} were made to a
program where {\tt s} were not defined.  WFS would assign the value
{\em false} to {\tt s}, but this is not always what humans do: rather
humans would treat the unknown predicate {\tt s} as in fact {\em
  unknown} or {\em undefined}.  More generally, if (sub-)goal $G$
refers to an undefined predicate,the {\em weak} completion semantics
(WCS) also assigns {\em undefined} to $G$, rather than {\em false} as
WFS does, or throwing an error (as XSB also does by default).

\begin{itemize}
\item For one or more tabled predicates ro use the completion semantics,
use the declaration

\noindent
{\tt \mif{} table {\em PredSpec} as compl\_semantics.}

\item Setting the ISO Prolog flag {\tt unknown} to {\tt undefined}
  makes calls to unknown predicates return the truth value {\em
    undefined}.  E.g., 
\begin{verbatim}
?- set_prolog_flag(unknown,undefined).
\end{verbatim}
This flag can also be set to the standard ISO values,
  {\tt fail}. {\tt warning} or {\tt error} (the last of which is the
    default).

\item The various forms of tabled negation work well with the
  completion semantics; however if mixing tabled and non-tabled
  predicates it is best to use {\tt not3/1} (cf. pg. \pageref{not3})
  rather than the SLD operators {\tt not/1} or \verb|\+/1|.
\end{itemize}

%\noindent
%These features can be set globally either separately or together:

%\begin{itemize}
%\item \item Setting the Prolog flag {\tt alt\_semantics} to {\tt cs} causes
%  XSB to globally evaluate the completion semantics.
%\item Setting the Prolog flag {\tt alt\_semantics} to {\tt weak\_cs} causes
%  XSB to globally evaluate the weak completion semantics, and is
%  equivalent to setting the {\tt alt\_semantics} flag to {\tt cs} and
%  the ISO flag {\tt unknown} to {\tt undefined}.
%\item Setting the Prolog flag {\tt alt\_semantics} to {\tt wfs} turns
%  causes XSB to behave in its default mode.  I.e., to globally
%  evaluate queries according to the well-founded semantics, and to
%  throw an error when encountering an unknown predicate.
%\end{itemize}

(W)CS and WFS can be mixed on a per-predicate basis.  If a goal
$G_{WFS}$ to a predicate declared to use WFS is involved in a loop
with a goal $G_{CS}$ declared to use CS, then $G_{WFS}$ is evaluated
according to the (W)CS.

\paragraph{Examples}

As a simple example, consider the program:
\begin{verbatim}
:- table simple_loop/1 as compl_semantics.
simple_loop(X):- simple_loop(X).     simple_loop(X):- p(X).
p(a).
\end{verbatim}
The query {\tt ?- simple\_loop(X)} returns two answers: {\tt X = a} as
{\em true}, and {\tt X} unbound as {\em undefined}.

For a more complex example, consider the program:
\begin{verbatim}
:- table m_1_1/1,m_1_2/1,m_1_3/1,m_1_4/1 as compl_semantics.
m_1_1(X):- m_1_2(X).         m_1_1(a):- m_1_2(a).
m_1_2(X):- m_1_3(X).         m_1_2(a):- m_1_3(a).         
m_1_3(X):- m_1_4(X),fail.    m_1_3(a):- m_1_4(a).
m_1_4(X):- m_1_1(X).         m_1_4(a):- m_1_1(a).
\end{verbatim}
%
The derivation of the query {\tt ?- m\_1\_1(X)} creates a positive SCC
with with numerous interrelated positive cycles, but these cycles can
be broken down into two groups.  The first group includes a dependency
edge from {\tt m\_1\_3(X)} to {\tt m\_1\_4(X)}, while the other set
does not include this edge.  Due to the first clause of {\tt
  m\_1\_3(X)}, all derivations in the first group fails, although
derivations that do not include this edge succeed.  Thus the only
answer to {\tt m\_1\_1(X)} has {\tt X = a} with truth value {\em
  undefined} (and a single delay list of {\tt [m\_1\_2(a)]}.


\index{tabling!call subsumption}
\index{tabling!call variance}
\index{tabling!answer subsumption}
\index{tabling!incremental}

\section{Compatibility of Tabling Modes and Predicate Attributes} \label{sec:tabling-compatibility}
%
As discussed in this chapter, there are numerous choices for how to
table a predicate. Either call subsumption or call variance may be
used, incremental tabling might or might not be used, and answer
subsumption might or might not be used.  Ground terms may be interned.
Furthermore, a tabled predicate, like any other predicate, may be
static or dynamic.
%and thread-shared or thread-private.
Additionally various abstraction methods may be used, such as subgoal
abstraction, answer abstraction, or maximal answers.
%And finally, a
%tabled predicate may be declared as private or shared in the
%multi-threaded engine.

To analyze further, all combinations are supported for call-variance
except for table indexing, which is a means of optimizing call
subsumption (cf. Section~\ref{sec:table-index}).
%and for thread-private predicates.
However, call subsumption has not been fully integrated with dynamic
code,
%or thread-shared predicates,
and cannot currently be combined
%with incremental tabling or
with answer subusmption.
%Similarly incremental tabling is not yet supported
%in the multi-threaded engine (it is supported for ``thread-private''
%computations only in the sequential engine).
All compatibilities are listed below: further combinations will be
supported in future versions of XSB as resources allow.

%The combinations in Table~\ref{table:table} allow full well-founded
%computation, constrained variables in calls and answers (including the
%residual program), and safe space reclamation, with the following
%exceptions.  Answer subsumption does support non lrd-stratified
%programs; and call subsumption does not yet support attributed
%variables in calls.  \index{attributed variables}

\begin{itemize}
\item A predicate $P$ declared with {\tt ans\_subsumption} cannot also
  be declared with {\tt answer\_abstract, compl\_semantics, dynamic,
    incremental, index/1, intern, opaque, subgoal\_abstract} or {\tt
    subsumptive}.
%
\item A predicate $P$ declared with {\tt answer\_abstract} cannot also
  be declared with {\tt ans\_subsumption, compl\_semantics, intern} or
  {\tt subsumptive}.
%
\item A predicate $P$ declared with {\tt compl\_semantics} cannot also
  be declared with {\tt ans\_subsumption, answer\_abstract, dynamic,
    incremental, index/1, intern, opaque, subsumptive} or {\tt subgoal\_abstract}.
%
\item A predicate $P$ declared with {\tt dyn} or {\tt (dynamic)}
  cannot also be declared with {\tt ans\_subsumption}, {\tt
    incremental} or {\tt subsumptive}.
%
\item A predicate $P$ declared with {\tt incremental} cannot also be
  declared with {\tt compl\_semantics, dynamic, index/1, intern,
    nonincremental} or {\tt opaque}.
  %, shared} or {\tt subsumptive}.
  However, $P$ may be changed from {\tt incremental} to {\tt
    nonincremental} or {\tt opaque} via {\tt
    set\_predicate\_property/2}.
%
\item A predicate $P$ declared with {\tt index/1} cannot also be
  declared with any option that is incompatible with {\tt subsumptive}
  since table indexing is a form of call subsumption.
%
\item A predicate $P$ declared with {\tt intern} cannot also be
  declared with {\tt ans\_subsumption, answer\_abstract,
    compl\_semantics, incremental, index/1, subgoal\_abstract} or {\tt
    subsumption}
%
\item A predicate $P$ declared with {\tt max\_answers} cannot also be
  declared with {\tt compl\_semantics, index/1} or {\tt subsumptive}.
%
\item A predicate $P$ declared with {\tt nonincremental} cannot also
  be declared with {\tt incremental} or {\tt opaque}.  However, $P$
  may be changed from {\tt nonincremental} to {\tt incremental} or
  {\tt opaque} via {\tt set\_predicate\_property/2}.
%
\item A predicate $P$ declared with {\tt opaque} cannot also be
  declared with {\tt incremental} or {\tt nonincremental}.  However,
  $P$ may be changed from {\tt opaque} to {\tt nonincremental} or {\tt
    incremental} via {\tt set\_predicate\_property/2}.
%
%\item A predicate $P$ declared with {\tt private} cannot also
%  be declared with {\tt shared}.
%
%\item A predicate $P$ declared with {\tt shared} cannot also be
%  declared with {\tt compl\_semantics, incremental, opaque, private}
%  or {\tt subsumptive}.
%
\item A predicate $P$ declared with {\tt subgoal\_abstract} cannot also
  be declared with {\tt index/1} or {\tt subsumptive}.
%
\item A predicate $P$ declared with {\tt subsumptive} cannot also be
  declared with {\tt compl\_semantics, dynamic, max\_answers}
%, shared}
    or {\tt subgoal\_abstract}.  However, $P$ may be changed from {\tt
      subsumptive} to {\tt variant} via {\tt
      set\_predicate\_property/2}.
%
\item A predicate $P$ declared with {\tt variant} cannot also be
  declared with {\tt index/1} or {\tt subsumptive}. However, $P$ may be changed from
  {\tt variant} to {\tt subsumptive} via {\tt
    set\_predicate\_property/2}.

\end{itemize}

%\begin{table}
%\begin{center}
%{\footnotesize
%\begin{tabular}{llllll}\hline \hline
%%variant/subsumptive & dynamic/static & shared/private & incremental/opaque  & answer subsumption  \\
%variant &	    static & 	   private &	  nonincremental &      no answer subsumption  &  yes \\
%%variant &	    static &	   private &	  nonincremental &      answer subsumption     &  yes \\
%variant	&	    static &	   private &      opaque &             no answer subsumption  &  yes \\
%variant &	    static &	   private &	  opaque &	      answer subsumption &	no \\
%variant &	    static &	   private &	  incremental &         no answer subsumption &	yes \\
%variant &	    static &	   private &      incremental &         answer subsumption &	no \\
%variant &	    static &	   shared &	  nonincremental &      no answer subsumption &	yes \\
%variant &	    static &	   shared &	  nonincremental &      answer subsumption &	yes \\
%variant &	    static &	   shared &	  opaque &	      no answer subsumption &	no \\
%variant &	    static &	   shared &	  opaque &	      answer subsumption &	no \\
%variant &	    static &	   shared &	  incremental &       no answer subsumption &	no \\
%variant &	    static &	   shared &	  incremental &          answer subsumption &	no \\
%variant &	    dynamic &	   private &	  nonincremental &      no answer subsumption &	yes \\
%ariant &	    dynamic &	   private &	  nonincremental &      answer subsumption &	yes \\
%variant &	    dynamic &	   private &	  opaque &	      no answer subsumption &	no \\
%variant &	    dynamic &	   private &	  opaque &	      answer subsumption &	no \\
%variant &	    dynamic &	   private &	  incremental &         no answer subsumption &	no \\
%%variant &	    dynamic &	   private &	  incremental &         answer subsumption &	no \\
%variant &	    dynamic &	   shared &	  nonincremental &      no answer subsumption &	yes \\
%variant &	    dynamic &	   shared &	  nonincremental &      answer subsumption &	yes \\
%variant &	    dynamic &	   shared &	  opaque &	      no answer subsumption &	no \\
%variant &	    dynamic &	   shared &	  opaque &	      answer subsumption &	no \\
%variant &	    dynamic &	   shared &	  incremental &         no answer subsumption &	no \\
%variant &	    dynamic &	   shared &	  incremental &         answer subsumption &	no \\
%subsumptive &	    static &	   private &	  nonincremental &      no answer subsumption &	yes \\
%subsumptive &	    static &	   private &	  nonincremental &      answer subsumption &	yes \\
%subsumptive &	    static &	   private &	  opaque &	      no answer subsumption &	no \\
%subsumptive &	    static &	   private &	  opaque &	      answer subsumption &	no \\
%subsumptive &	    static &	   private &	  incremental &         no answer subsumption &	no \\
%subsumptive &	    static &	   private &	  incremental &         answer subsumption &	no \\
%subsumptive &	    static &	   shared &	  nonincremental &      no answer subsumption &	no \\
%subsumptive &	    static &	   shared &	  nonincremental &      answer subsumption &	no \\
%subsumptive &	    static &	   shared &	  opaque &	      no answer subsumption &	no \\
%subsumptive &	    static &	   shared &	  opaque &	      answer subsumption &	no \\
%subsumptive &	    static &	   shared &	  incremental &       no answer subsumption &	no \\
%subsumptive &	    static &	   shared &	  incremental &          answer subsumption &	no \\
%subsumptive &	    dynamic &	   private &	  nonincremental &      no answer subsumption &	yes \\
%subsumptive &	    dynamic &	   private &	  nonincremental &      answer subsumption &	yes \\
%subsumptive &	    dynamic &	   private &	  opaque &	      no answer subsumption &	no \\
%subsumptive &	    dynamic &	   private &	  opaque &	      answer subsumption &	no \\
%subsumptive &	    dynamic &	   private &	  incremental &         no answer subsumption &	no \\
%subsumptive &	    dynamic &	   private &   	  incremental &         answer subsumption &	no \\
%subsumptive &	    dynamic &	   shared &	  nonincremental &      no answer subsumption &	no \\
%subsumptive &	    dynamic &	   shared &	  nonincremental &      answer subsumption &	no \\
%subsumptive &	    dynamic &	   shared &	  opaque &	      no answer subsumption &	no \\
%subsumptive &	    dynamic &	   shared &	  opaque &	      answer subsumption &	no \\
%subsumptive &	    dynamic &	   shared &	  incremental &         no answer subsumption &	no \\
%subsumptive &  	    dynamic &	   shared &	  incremental &         answer subsumption &	no \\ \hline \hline 
%\end{tabular}
%}
%\end{center}
%\caption{Support for different tabling modes in XSB \version}
%\label{table:table}
%\end{table}

